{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Use Case - Tayko Software Cataloger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pylab as plt\\nimport seaborn as sns\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.preprocessing import StandardScaler\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.compose import ColumnTransformer\\n\\nimport dmba\\nfrom dmba import (\\n    regressionSummary,\\n    adjusted_r2_score,\\n    AIC_score,\\n    BIC_score,\\n    classificationSummary,\\n    gainsChart,\\n    liftChart,\\n    stepwise_selection,\\n)\\n\\nfrom fast_ml import eda\\n\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pylab as plt\\nimport seaborn as sns\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.preprocessing import StandardScaler\\n\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.compose import ColumnTransformer\\n\\nimport dmba\\nfrom dmba import (\\n    regressionSummary,\\n    adjusted_r2_score,\\n    AIC_score,\\n    BIC_score,\\n    classificationSummary,\\n    gainsChart,\\n    liftChart,\\n    stepwise_selection,\\n)\\n\\nfrom fast_ml import eda\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import dmba\n",
    "from dmba import (\n",
    "    regressionSummary,\n",
    "    adjusted_r2_score,\n",
    "    AIC_score,\n",
    "    BIC_score,\n",
    "    classificationSummary,\n",
    "    gainsChart,\n",
    "    liftChart,\n",
    "    stepwise_selection,\n",
    ")\n",
    "\n",
    "from fast_ml import eda\n",
    "\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>data_type_grp</th>\n",
       "      <th>num_unique_values</th>\n",
       "      <th>sample_unique_values</th>\n",
       "      <th>num_missing</th>\n",
       "      <th>perc_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sequence_number</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2000</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_a</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_c</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_b</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_d</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_e</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_m</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_o</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_h</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_r</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_s</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_t</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_u</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_p</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_x</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_w</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>15</td>\n",
       "      <td>[2, 0, 1, 4, 5, 3, 9, 8, 6, 10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>940</td>\n",
       "      <td>[3662, 2900, 3883, 829, 869, 1995, 1498, 3397,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>923</td>\n",
       "      <td>[3662, 2900, 3914, 829, 869, 2002, 1529, 3397,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Web order</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender=male</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Address_is_res</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spending</th>\n",
       "      <td>int64</td>\n",
       "      <td>Numerical</td>\n",
       "      <td>363</td>\n",
       "      <td>[128, 0, 127, 489, 174, 1416, 192, 130, 386, 161]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data_type data_type_grp num_unique_values  \\\n",
       "sequence_number          int64     Numerical              2000   \n",
       "US                       int64     Numerical                 2   \n",
       "source_a                 int64     Numerical                 2   \n",
       "source_c                 int64     Numerical                 2   \n",
       "source_b                 int64     Numerical                 2   \n",
       "source_d                 int64     Numerical                 2   \n",
       "source_e                 int64     Numerical                 2   \n",
       "source_m                 int64     Numerical                 2   \n",
       "source_o                 int64     Numerical                 2   \n",
       "source_h                 int64     Numerical                 2   \n",
       "source_r                 int64     Numerical                 2   \n",
       "source_s                 int64     Numerical                 2   \n",
       "source_t                 int64     Numerical                 2   \n",
       "source_u                 int64     Numerical                 2   \n",
       "source_p                 int64     Numerical                 2   \n",
       "source_x                 int64     Numerical                 2   \n",
       "source_w                 int64     Numerical                 2   \n",
       "Freq                     int64     Numerical                15   \n",
       "last_update_days_ago     int64     Numerical               940   \n",
       "1st_update_days_ago      int64     Numerical               923   \n",
       "Web order                int64     Numerical                 2   \n",
       "Gender=male              int64     Numerical                 2   \n",
       "Address_is_res           int64     Numerical                 2   \n",
       "Purchase                 int64     Numerical                 2   \n",
       "Spending                 int64     Numerical               363   \n",
       "\n",
       "                                                   sample_unique_values  \\\n",
       "sequence_number                         [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   \n",
       "US                                                               [1, 0]   \n",
       "source_a                                                         [0, 1]   \n",
       "source_c                                                         [0, 1]   \n",
       "source_b                                                         [1, 0]   \n",
       "source_d                                                         [0, 1]   \n",
       "source_e                                                         [0, 1]   \n",
       "source_m                                                         [0, 1]   \n",
       "source_o                                                         [0, 1]   \n",
       "source_h                                                         [0, 1]   \n",
       "source_r                                                         [0, 1]   \n",
       "source_s                                                         [0, 1]   \n",
       "source_t                                                         [0, 1]   \n",
       "source_u                                                         [0, 1]   \n",
       "source_p                                                         [0, 1]   \n",
       "source_x                                                         [0, 1]   \n",
       "source_w                                                         [0, 1]   \n",
       "Freq                                    [2, 0, 1, 4, 5, 3, 9, 8, 6, 10]   \n",
       "last_update_days_ago  [3662, 2900, 3883, 829, 869, 1995, 1498, 3397,...   \n",
       "1st_update_days_ago   [3662, 2900, 3914, 829, 869, 2002, 1529, 3397,...   \n",
       "Web order                                                        [1, 0]   \n",
       "Gender=male                                                      [0, 1]   \n",
       "Address_is_res                                                   [1, 0]   \n",
       "Purchase                                                         [1, 0]   \n",
       "Spending              [128, 0, 127, 489, 174, 1416, 192, 130, 386, 161]   \n",
       "\n",
       "                     num_missing perc_missing  \n",
       "sequence_number                0            0  \n",
       "US                             0            0  \n",
       "source_a                       0            0  \n",
       "source_c                       0            0  \n",
       "source_b                       0            0  \n",
       "source_d                       0            0  \n",
       "source_e                       0            0  \n",
       "source_m                       0            0  \n",
       "source_o                       0            0  \n",
       "source_h                       0            0  \n",
       "source_r                       0            0  \n",
       "source_s                       0            0  \n",
       "source_t                       0            0  \n",
       "source_u                       0            0  \n",
       "source_p                       0            0  \n",
       "source_x                       0            0  \n",
       "source_w                       0            0  \n",
       "Freq                           0            0  \n",
       "last_update_days_ago           0            0  \n",
       "1st_update_days_ago            0            0  \n",
       "Web order                      0            0  \n",
       "Gender=male                    0            0  \n",
       "Address_is_res                 0            0  \n",
       "Purchase                       0            0  \n",
       "Spending                       0            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Load Data\\ncat_df = pd.read_csv(\\n    \\\"/Users/datascience/Desktop/Applied Data Science for Buisiness/Datasets/Tayko Software Cataloger.csv\\\"\\n)\\neda.df_info(cat_df)  # Quick Exploratory Data Analysis\";\n",
       "                var nbb_formatted_code = \"# Load Data\\ncat_df = pd.read_csv(\\n    \\\"/Users/datascience/Desktop/Applied Data Science for Buisiness/Datasets/Tayko Software Cataloger.csv\\\"\\n)\\neda.df_info(cat_df)  # Quick Exploratory Data Analysis\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Data\n",
    "cat_df = pd.read_csv(\n",
    "    \"/Users/datascience/Desktop/Applied Data Science for Buisiness/Datasets/Tayko Software Cataloger.csv\"\n",
    ")\n",
    "eda.df_info(cat_df)  # Quick Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Each catalog costs approximately 2 dollars to mail (including printing, postage, and mailing costs). Estimate the gross profit that the firm could expect from the remaining 180,000 names if it selects them randomly from the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Spending for 1000 purchasers: $ 205.249\n",
      "Estimate gross profit that the firm could expect from the remaining 180,000 names: $ 1616557.5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Calculate average spending from the 1,000 purchasers in the stratified sample\\npurchasers_df = cat_df[cat_df[\\\"Purchase\\\"] == 1]\\nprint(\\n    \\\"Average Spending for 1000 purchasers: $\\\",\\n    purchasers_df.Spending.mean(),\\n)\\n\\n# Calculate average spending from the 2000 customers in the stratified sample\\navg_spending = cat_df.Spending.mean()\\n# Expected average spending per customer\\nnumber_purchasers = (\\n    180000 * 0.107\\n)  # random selection probability of purchase (true response rate)\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * 180000\\navg_profit = total_spending - cost\\nprint(\\n    \\\"Estimate gross profit that the firm could expect from the remaining 180,000 names: $\\\",\\n    avg_profit,\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate average spending from the 1,000 purchasers in the stratified sample\\npurchasers_df = cat_df[cat_df[\\\"Purchase\\\"] == 1]\\nprint(\\n    \\\"Average Spending for 1000 purchasers: $\\\",\\n    purchasers_df.Spending.mean(),\\n)\\n\\n# Calculate average spending from the 2000 customers in the stratified sample\\navg_spending = cat_df.Spending.mean()\\n# Expected average spending per customer\\nnumber_purchasers = (\\n    180000 * 0.107\\n)  # random selection probability of purchase (true response rate)\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * 180000\\navg_profit = total_spending - cost\\nprint(\\n    \\\"Estimate gross profit that the firm could expect from the remaining 180,000 names: $\\\",\\n    avg_profit,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate average spending from the 1,000 purchasers in the stratified sample\n",
    "purchasers_df = cat_df[cat_df[\"Purchase\"] == 1]\n",
    "print(\n",
    "    \"Average Spending for 1000 purchasers: $\",\n",
    "    purchasers_df.Spending.mean(),\n",
    ")\n",
    "\n",
    "# Calculate average spending from the 2000 customers in the stratified sample\n",
    "avg_spending = cat_df.Spending.mean()\n",
    "# Expected average spending per customer\n",
    "number_purchasers = (\n",
    "    180000 * 0.107\n",
    ")  # random selection probability of purchase (true response rate)\n",
    "total_spending = number_purchasers * avg_spending\n",
    "\n",
    "# Expected average profit per customer (with cost of mailing)\n",
    "cost = 2 * 180000\n",
    "avg_profit = total_spending - cost\n",
    "print(\n",
    "    \"Estimate gross profit that the firm could expect from the remaining 180,000 names: $\",\n",
    "    avg_profit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Develop a model for classifying a customer as a purchaser or nonpurchaser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Partition the data randomly into a training set (800 records), validation set (700 records), and test set (500 records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Train, Validation, Test Split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 22)\n",
      "X_valid shape: (700, 22)\n",
      "X_test shape: (500, 22)\n",
      "y_train shape: (800, 2)\n",
      "y_valid shape: (700, 2)\n",
      "y_test shape: (500, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"X = cat_df.drop(columns=[\\\"Purchase\\\", \\\"Spending\\\", \\\"sequence_number\\\"])\\ny = cat_df[[\\\"Purchase\\\", \\\"Spending\\\"]]\\nclasses = [\\\"nonpurchasers\\\", \\\"purchasers\\\"]\\n# Split Dataset into Train/Test\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X,\\n    y,\\n    test_size=0.25,\\n    shuffle=True,\\n    random_state=1,\\n)\\n\\n# Split Train into Train/Valid\\nX_train, X_valid, y_train, y_valid = train_test_split(\\n    X_train, y_train, test_size=700, shuffle=True, random_state=1\\n)\\n\\n\\nprint(\\\"X_train shape: {}\\\".format(X_train.shape))\\nprint(\\\"X_valid shape: {}\\\".format(X_valid.shape))\\nprint(\\\"X_test shape: {}\\\".format(X_test.shape))\\nprint(\\\"y_train shape: {}\\\".format(y_train.shape))\\nprint(\\\"y_valid shape: {}\\\".format(y_valid.shape))\\nprint(\\\"y_test shape: {}\\\".format(y_test.shape))\";\n",
       "                var nbb_formatted_code = \"X = cat_df.drop(columns=[\\\"Purchase\\\", \\\"Spending\\\", \\\"sequence_number\\\"])\\ny = cat_df[[\\\"Purchase\\\", \\\"Spending\\\"]]\\nclasses = [\\\"nonpurchasers\\\", \\\"purchasers\\\"]\\n# Split Dataset into Train/Test\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X,\\n    y,\\n    test_size=0.25,\\n    shuffle=True,\\n    random_state=1,\\n)\\n\\n# Split Train into Train/Valid\\nX_train, X_valid, y_train, y_valid = train_test_split(\\n    X_train, y_train, test_size=700, shuffle=True, random_state=1\\n)\\n\\n\\nprint(\\\"X_train shape: {}\\\".format(X_train.shape))\\nprint(\\\"X_valid shape: {}\\\".format(X_valid.shape))\\nprint(\\\"X_test shape: {}\\\".format(X_test.shape))\\nprint(\\\"y_train shape: {}\\\".format(y_train.shape))\\nprint(\\\"y_valid shape: {}\\\".format(y_valid.shape))\\nprint(\\\"y_test shape: {}\\\".format(y_test.shape))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = cat_df.drop(columns=[\"Purchase\", \"Spending\", \"sequence_number\"])\n",
    "y = cat_df[[\"Purchase\", \"Spending\"]]\n",
    "classes = [\"nonpurchasers\", \"purchasers\"]\n",
    "# Split Dataset into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    shuffle=True,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Split Train into Train/Valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=700, shuffle=True, random_state=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_valid shape: {}\".format(X_valid.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_valid shape: {}\".format(y_valid.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Preprocess_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# list for cols to scale\\ncols_to_scale = [\\\"Freq\\\", \\\"last_update_days_ago\\\", \\\"1st_update_days_ago\\\"]\\n\\n# create and fit scaler\\nscaler = StandardScaler()\\nscaler.fit(X_train[cols_to_scale])\\n\\n# scale selected data\\nX_train[cols_to_scale] = scaler.transform(X_train[cols_to_scale])\\nX_valid[cols_to_scale] = scaler.transform(X_valid[cols_to_scale])\\nX_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\";\n",
       "                var nbb_formatted_code = \"# list for cols to scale\\ncols_to_scale = [\\\"Freq\\\", \\\"last_update_days_ago\\\", \\\"1st_update_days_ago\\\"]\\n\\n# create and fit scaler\\nscaler = StandardScaler()\\nscaler.fit(X_train[cols_to_scale])\\n\\n# scale selected data\\nX_train[cols_to_scale] = scaler.transform(X_train[cols_to_scale])\\nX_valid[cols_to_scale] = scaler.transform(X_valid[cols_to_scale])\\nX_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list for cols to scale\n",
    "cols_to_scale = [\"Freq\", \"last_update_days_ago\", \"1st_update_days_ago\"]\n",
    "\n",
    "# create and fit scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[cols_to_scale])\n",
    "\n",
    "# scale selected data\n",
    "X_train[cols_to_scale] = scaler.transform(X_train[cols_to_scale])\n",
    "X_valid[cols_to_scale] = scaler.transform(X_valid[cols_to_scale])\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Run logistic regression with L2 penalty, using method LogisticRegressionCV, to select the best subset of variables, then use this model to classify the data into purchasers and nonpurchasers. Use only the training set for running the model. (Logistic regression is used because it yields an estimated “probability of purchase,” which is required later in the analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  -0.42447313588136415\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>0.350886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_a</td>\n",
       "      <td>1.553138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_c</td>\n",
       "      <td>-0.706147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_b</td>\n",
       "      <td>-0.138045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_d</td>\n",
       "      <td>0.885746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source_e</td>\n",
       "      <td>0.494972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>source_m</td>\n",
       "      <td>0.755940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>source_o</td>\n",
       "      <td>0.336890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>source_h</td>\n",
       "      <td>-4.144494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>source_r</td>\n",
       "      <td>0.369997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>source_s</td>\n",
       "      <td>-0.120527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>source_t</td>\n",
       "      <td>1.198233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>source_u</td>\n",
       "      <td>1.717244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>source_p</td>\n",
       "      <td>1.432897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>source_x</td>\n",
       "      <td>0.723098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>source_w</td>\n",
       "      <td>1.187598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Freq</td>\n",
       "      <td>3.137663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>last_update_days_ago</td>\n",
       "      <td>0.302429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1st_update_days_ago</td>\n",
       "      <td>-0.381637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Web order</td>\n",
       "      <td>0.752754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gender=male</td>\n",
       "      <td>-0.317367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Address_is_res</td>\n",
       "      <td>-0.698421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predictor  coefficient\n",
       "0                     US     0.350886\n",
       "1               source_a     1.553138\n",
       "2               source_c    -0.706147\n",
       "3               source_b    -0.138045\n",
       "4               source_d     0.885746\n",
       "5               source_e     0.494972\n",
       "6               source_m     0.755940\n",
       "7               source_o     0.336890\n",
       "8               source_h    -4.144494\n",
       "9               source_r     0.369997\n",
       "10              source_s    -0.120527\n",
       "11              source_t     1.198233\n",
       "12              source_u     1.717244\n",
       "13              source_p     1.432897\n",
       "14              source_x     0.723098\n",
       "15              source_w     1.187598\n",
       "16                  Freq     3.137663\n",
       "17  last_update_days_ago     0.302429\n",
       "18   1st_update_days_ago    -0.381637\n",
       "19             Web order     0.752754\n",
       "20           Gender=male    -0.317367\n",
       "21        Address_is_res    -0.698421"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "               Mean Error (ME) : -0.0025\n",
      "Root Mean Squared Error (RMSE) : 0.4000\n",
      "     Mean Absolute Error (MAE) : 0.1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Logistic Regression\\nlogit_full = LogisticRegressionCV(penalty=\\\"l2\\\", cv=5, max_iter=1000)\\nlogit_full.fit(X_train, y_train[\\\"Purchase\\\"])\\n\\n# print coefficients\\nlist_full = pd.DataFrame({\\\"Predictor\\\": X.columns,\\n                          \\\"coefficient\\\": logit_full.coef_[0]})\\nprint(\\\"intercept \\\", logit_full.intercept_[0])\\ndisplay(list_full)\\n\\n# print performance measures\\ndisplay(regressionSummary(y_train[\\\"Purchase\\\"], logit_full.predict(X_train)))\";\n",
       "                var nbb_formatted_code = \"# Logistic Regression\\nlogit_full = LogisticRegressionCV(penalty=\\\"l2\\\", cv=5, max_iter=1000)\\nlogit_full.fit(X_train, y_train[\\\"Purchase\\\"])\\n\\n# print coefficients\\nlist_full = pd.DataFrame({\\\"Predictor\\\": X.columns, \\\"coefficient\\\": logit_full.coef_[0]})\\nprint(\\\"intercept \\\", logit_full.intercept_[0])\\ndisplay(list_full)\\n\\n# print performance measures\\ndisplay(regressionSummary(y_train[\\\"Purchase\\\"], logit_full.predict(X_train)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit_full = LogisticRegressionCV(penalty=\"l2\", cv=5, max_iter=1000)\n",
    "logit_full.fit(X_train, y_train[\"Purchase\"])\n",
    "\n",
    "# print coefficients\n",
    "list_full = pd.DataFrame({\"Predictor\": X.columns,\n",
    "                          \"coefficient\": logit_full.coef_[0]})\n",
    "print(\"intercept \", logit_full.intercept_[0])\n",
    "display(list_full)\n",
    "\n",
    "# print performance measures\n",
    "display(regressionSummary(y_train[\"Purchase\"],\n",
    "                          logit_full.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Metrics for using all predictors in X_train -\n",
      "adjusted r2 :  0.35916194784703503\n",
      "AIC :  810.2364821288279\n",
      "BIC :  824.2903173118317\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# get predictions based on train_x\\npred_y = logit_full.predict(X_train)\\n\\n# calculate adjusted r2 and information criteria measures\\nprint(\\\"- Metrics for using all predictors in X_train -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_train[\\\"Purchase\\\"],\\n                                          pred_y, logit_full))\\nprint(\\\"AIC : \\\", AIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_full))\\nprint(\\\"BIC : \\\", BIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_full))\";\n",
       "                var nbb_formatted_code = \"# get predictions based on train_x\\npred_y = logit_full.predict(X_train)\\n\\n# calculate adjusted r2 and information criteria measures\\nprint(\\\"- Metrics for using all predictors in X_train -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_train[\\\"Purchase\\\"], pred_y, logit_full))\\nprint(\\\"AIC : \\\", AIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_full))\\nprint(\\\"BIC : \\\", BIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_full))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get predictions based on train_x\n",
    "pred_y = logit_full.predict(X_train)\n",
    "\n",
    "# calculate adjusted r2 and information criteria measures\n",
    "print(\"- Metrics for using all predictors in X_train -\")\n",
    "print(\"adjusted r2 : \", adjusted_r2_score(y_train[\"Purchase\"], pred_y, logit_full))\n",
    "print(\"AIC : \", AIC_score(y_train[\"Purchase\"], pred_y, logit_full))\n",
    "print(\"BIC : \", BIC_score(y_train[\"Purchase\"], pred_y, logit_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  -0.20418475029769784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source_a</td>\n",
       "      <td>1.388706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source_c</td>\n",
       "      <td>-0.636068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source_d</td>\n",
       "      <td>0.786423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_e</td>\n",
       "      <td>0.345984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_m</td>\n",
       "      <td>0.736049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source_h</td>\n",
       "      <td>-4.119148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>source_t</td>\n",
       "      <td>1.056473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>source_u</td>\n",
       "      <td>1.586167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>source_p</td>\n",
       "      <td>1.292274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>source_x</td>\n",
       "      <td>0.800315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>source_w</td>\n",
       "      <td>1.171684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Freq</td>\n",
       "      <td>2.996690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Web order</td>\n",
       "      <td>0.758606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Address_is_res</td>\n",
       "      <td>-0.641128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Predictor  coefficient\n",
       "0         source_a     1.388706\n",
       "1         source_c    -0.636068\n",
       "2         source_d     0.786423\n",
       "3         source_e     0.345984\n",
       "4         source_m     0.736049\n",
       "5         source_h    -4.119148\n",
       "6         source_t     1.056473\n",
       "7         source_u     1.586167\n",
       "8         source_p     1.292274\n",
       "9         source_x     0.800315\n",
       "10        source_w     1.171684\n",
       "11            Freq     2.996690\n",
       "12       Web order     0.758606\n",
       "13  Address_is_res    -0.641128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression statistics\n",
      "\n",
      "               Mean Error (ME) : -0.0050\n",
      "Root Mean Squared Error (RMSE) : 0.4062\n",
      "     Mean Absolute Error (MAE) : 0.1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Confustion Matrix -\n",
      "Confusion Matrix (Accuracy 0.8350)\n",
      "\n",
      "              Prediction\n",
      "       Actual nonpurchasers    purchasers\n",
      "nonpurchasers           329            68\n",
      "   purchasers            64           339\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Select Subset based on Logistic Regression CV coefficients\\nlist_full[\\\"coefficient\\\"] = list_full[\\\"coefficient\\\"].abs()\\nreduced_list = list_full[list_full[\\\"coefficient\\\"] >= 0.4]\\npredictors = reduced_list[\\\"Predictor\\\"].unique()\\n\\n\\n# Logistic Regression\\nlogit_red = LogisticRegressionCV(penalty=\\\"l2\\\", cv=5, max_iter=1000)\\nlogit_red.fit(X_train[predictors], y_train[\\\"Purchase\\\"])\\n\\n# print coefficients\\nlist_red = pd.DataFrame(\\n    {\\\"Predictor\\\": X_train[predictors].columns,\\n     \\\"coefficient\\\": logit_red.coef_[0]}\\n)\\nprint(\\\"intercept \\\", logit_red.intercept_[0])\\ndisplay(list_red)\\n\\n# print performance measures\\ndisplay(regressionSummary(y_train[\\\"Purchase\\\"],\\n                          logit_red.predict(X_train[predictors])))\\n\\nlogit_red_pred = logit_red.predict_proba(X_train[predictors])\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_train[\\\"Purchase\\\"],\\n        \\\"p(0)\\\": [p[0] for p in logit_red_pred],\\n        \\\"p(1)\\\": [p[1] for p in logit_red_pred],\\n        \\\"predicted\\\": logit_red.predict(X_train[predictors]),\\n    }\\n)\\nred_result = red_result.sort_values(by=[\\\"p(1)\\\"], ascending=False)\\n\\n# confusion matrix\\nprint(\\\"- Confustion Matrix -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted,\\n                      class_names=classes)\";\n",
       "                var nbb_formatted_code = \"# Select Subset based on Logistic Regression CV coefficients\\nlist_full[\\\"coefficient\\\"] = list_full[\\\"coefficient\\\"].abs()\\nreduced_list = list_full[list_full[\\\"coefficient\\\"] >= 0.4]\\npredictors = reduced_list[\\\"Predictor\\\"].unique()\\n\\n\\n# Logistic Regression\\nlogit_red = LogisticRegressionCV(penalty=\\\"l2\\\", cv=5, max_iter=1000)\\nlogit_red.fit(X_train[predictors], y_train[\\\"Purchase\\\"])\\n\\n# print coefficients\\nlist_red = pd.DataFrame(\\n    {\\\"Predictor\\\": X_train[predictors].columns, \\\"coefficient\\\": logit_red.coef_[0]}\\n)\\nprint(\\\"intercept \\\", logit_red.intercept_[0])\\ndisplay(list_red)\\n\\n# print performance measures\\ndisplay(regressionSummary(y_train[\\\"Purchase\\\"], logit_red.predict(X_train[predictors])))\\n\\nlogit_red_pred = logit_red.predict_proba(X_train[predictors])\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_train[\\\"Purchase\\\"],\\n        \\\"p(0)\\\": [p[0] for p in logit_red_pred],\\n        \\\"p(1)\\\": [p[1] for p in logit_red_pred],\\n        \\\"predicted\\\": logit_red.predict(X_train[predictors]),\\n    }\\n)\\nred_result = red_result.sort_values(by=[\\\"p(1)\\\"], ascending=False)\\n\\n# confusion matrix\\nprint(\\\"- Confustion Matrix -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted, class_names=classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select Subset based on Logistic Regression CV coefficients\n",
    "list_full[\"coefficient\"] = list_full[\"coefficient\"].abs()\n",
    "reduced_list = list_full[list_full[\"coefficient\"] >= 0.4]\n",
    "predictors = reduced_list[\"Predictor\"].unique()\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "logit_red = LogisticRegressionCV(penalty=\"l2\", cv=5, max_iter=1000)\n",
    "logit_red.fit(X_train[predictors], y_train[\"Purchase\"])\n",
    "\n",
    "# print coefficients\n",
    "list_red = pd.DataFrame(\n",
    "    {\"Predictor\": X_train[predictors].columns, \"coefficient\": logit_red.coef_[0]}\n",
    ")\n",
    "print(\"intercept \", logit_red.intercept_[0])\n",
    "display(list_red)\n",
    "\n",
    "# print performance measures\n",
    "display(regressionSummary(y_train[\"Purchase\"], logit_red.predict(X_train[predictors])))\n",
    "\n",
    "logit_red_pred = logit_red.predict_proba(X_train[predictors])\n",
    "red_result = pd.DataFrame(\n",
    "    {\n",
    "        \"actual\": y_train[\"Purchase\"],\n",
    "        \"p(0)\": [p[0] for p in logit_red_pred],\n",
    "        \"p(1)\": [p[1] for p in logit_red_pred],\n",
    "        \"predicted\": logit_red.predict(X_train[predictors]),\n",
    "    }\n",
    ")\n",
    "red_result = red_result.sort_values(by=[\"p(1)\"], ascending=False)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"- Confustion Matrix -\")\n",
    "classificationSummary(red_result.actual, red_result.predicted, class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Metrics for using a reduced set of predictors -\n",
      "adjusted r2 :  0.339135758717255\n",
      "AIC :  834.853809062231\n",
      "BIC :  848.9076442452348\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# get predictions based on train_x\\npred_y = logit_red.predict(X_train[predictors])\\n\\n# calculate adjusted r2 and information criteria measures\\nprint(\\\"- Metrics for using a reduced set of predictors -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_train[\\\"Purchase\\\"],\\n                                          pred_y, logit_red))\\nprint(\\\"AIC : \\\", AIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_red))\\nprint(\\\"BIC : \\\", BIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_red))\";\n",
       "                var nbb_formatted_code = \"# get predictions based on train_x\\npred_y = logit_red.predict(X_train[predictors])\\n\\n# calculate adjusted r2 and information criteria measures\\nprint(\\\"- Metrics for using a reduced set of predictors -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_train[\\\"Purchase\\\"], pred_y, logit_red))\\nprint(\\\"AIC : \\\", AIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_red))\\nprint(\\\"BIC : \\\", BIC_score(y_train[\\\"Purchase\\\"], pred_y, logit_red))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get predictions based on train_x\n",
    "pred_y = logit_red.predict(X_train[predictors])\n",
    "\n",
    "# calculate adjusted r2 and information criteria measures\n",
    "print(\"- Metrics for using a reduced set of predictors -\")\n",
    "print(\"adjusted r2 : \", adjusted_r2_score(y_train[\"Purchase\"], pred_y, logit_red))\n",
    "print(\"AIC : \", AIC_score(y_train[\"Purchase\"], pred_y, logit_red))\n",
    "print(\"BIC : \", BIC_score(y_train[\"Purchase\"], pred_y, logit_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Confusion Matrix for using a reduced set of predictors -\n",
      "Confusion Matrix (Accuracy 0.8350)\n",
      "\n",
      "              Prediction\n",
      "       Actual nonpurchasers    purchasers\n",
      "nonpurchasers           329            68\n",
      "   purchasers            64           339\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"logit_red_pred = logit_red.predict_proba(X_train[predictors])\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_train[\\\"Purchase\\\"],\\n        \\\"p(0)\\\": [p[0] for p in logit_red_pred],\\n        \\\"p(1)\\\": [p[1] for p in logit_red_pred],\\n        \\\"predicted\\\": logit_red.predict(X_train[predictors]),\\n    }\\n)\\nred_result = red_result.sort_values(by=[\\\"p(1)\\\"], ascending=False)\\n\\n# confusion matrix\\nprint(\\\"- Confusion Matrix for using a reduced set of predictors -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted,\\n                      class_names=classes)\";\n",
       "                var nbb_formatted_code = \"logit_red_pred = logit_red.predict_proba(X_train[predictors])\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_train[\\\"Purchase\\\"],\\n        \\\"p(0)\\\": [p[0] for p in logit_red_pred],\\n        \\\"p(1)\\\": [p[1] for p in logit_red_pred],\\n        \\\"predicted\\\": logit_red.predict(X_train[predictors]),\\n    }\\n)\\nred_result = red_result.sort_values(by=[\\\"p(1)\\\"], ascending=False)\\n\\n# confusion matrix\\nprint(\\\"- Confusion Matrix for using a reduced set of predictors -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted, class_names=classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_red_pred = logit_red.predict_proba(X_train[predictors])\n",
    "red_result = pd.DataFrame(\n",
    "    {\n",
    "        \"actual\": y_train[\"Purchase\"],\n",
    "        \"p(0)\": [p[0] for p in logit_red_pred],\n",
    "        \"p(1)\": [p[1] for p in logit_red_pred],\n",
    "        \"predicted\": logit_red.predict(X_train[predictors]),\n",
    "    }\n",
    ")\n",
    "red_result = red_result.sort_values(by=[\"p(1)\"], ascending=False)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"- Confusion Matrix for using a reduced set of predictors -\")\n",
    "classificationSummary(red_result.actual, red_result.predicted, class_names=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Develop a model for predicting spending among the purchasers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Create subsets of the training and validation sets for only purchasers’ records by filtering for Purchase = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Filter dataset\\npurchasers_df = cat_df[cat_df[\\\"Purchase\\\"] == 1]\\nX_pur = purchasers_df.drop(columns=[\\\"Purchase\\\", \\\"Spending\\\",\\n                                    \\\"sequence_number\\\"])\\ny_pur = purchasers_df[\\\"Spending\\\"]\\n\\n# Split Dataset into Train/Valid\\nX_train_pur, X_valid_pur, y_train_pur, y_valid_pur = train_test_split(\\n    X_pur, y_pur, test_size=0.40, shuffle=True, random_state=1\\n)\";\n",
       "                var nbb_formatted_code = \"# Filter dataset\\npurchasers_df = cat_df[cat_df[\\\"Purchase\\\"] == 1]\\nX_pur = purchasers_df.drop(columns=[\\\"Purchase\\\", \\\"Spending\\\", \\\"sequence_number\\\"])\\ny_pur = purchasers_df[\\\"Spending\\\"]\\n\\n# Split Dataset into Train/Valid\\nX_train_pur, X_valid_pur, y_train_pur, y_valid_pur = train_test_split(\\n    X_pur, y_pur, test_size=0.40, shuffle=True, random_state=1\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter dataset\n",
    "purchasers_df = cat_df[cat_df[\"Purchase\"] == 1]\n",
    "X_pur = purchasers_df.drop(columns=[\"Purchase\", \"Spending\", \"sequence_number\"])\n",
    "y_pur = purchasers_df[\"Spending\"]\n",
    "\n",
    "# Split Dataset into Train/Valid\n",
    "X_train_pur, X_valid_pur, y_train_pur, y_valid_pur = train_test_split(\n",
    "    X_pur, y_pur, test_size=0.40, shuffle=True, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# list for cols to scale\\ncols_to_scale = [\\\"Freq\\\", \\\"last_update_days_ago\\\", \\\"1st_update_days_ago\\\"]\\n\\n# create and fit scaler\\nscaler = StandardScaler()\\nscaler.fit(X_train_pur[cols_to_scale])\\n\\n# scale selected data\\nX_train_pur[cols_to_scale] = scaler.transform(X_train_pur[cols_to_scale])\\nX_valid_pur[cols_to_scale] = scaler.transform(X_valid_pur[cols_to_scale])\";\n",
       "                var nbb_formatted_code = \"# list for cols to scale\\ncols_to_scale = [\\\"Freq\\\", \\\"last_update_days_ago\\\", \\\"1st_update_days_ago\\\"]\\n\\n# create and fit scaler\\nscaler = StandardScaler()\\nscaler.fit(X_train_pur[cols_to_scale])\\n\\n# scale selected data\\nX_train_pur[cols_to_scale] = scaler.transform(X_train_pur[cols_to_scale])\\nX_valid_pur[cols_to_scale] = scaler.transform(X_valid_pur[cols_to_scale])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list for cols to scale\n",
    "cols_to_scale = [\"Freq\", \"last_update_days_ago\", \"1st_update_days_ago\"]\n",
    "\n",
    "# create and fit scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_pur[cols_to_scale])\n",
    "\n",
    "# scale selected data\n",
    "X_train_pur[cols_to_scale] = scaler.transform(X_train_pur[cols_to_scale])\n",
    "X_valid_pur[cols_to_scale] = scaler.transform(X_valid_pur[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Develop models for predicting spending with the filtered datasets, using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: US, source_a, source_c, source_b, source_d, source_e, source_m, source_o, source_h, source_r, source_s, source_t, source_u, source_p, source_x, source_w, Freq, last_update_days_ago, 1st_update_days_ago, Web order, Gender=male, Address_is_res\n",
      "Start: score=8123.51, constant\n",
      "Step: score=7834.90, add Freq\n",
      "Step: score=7814.54, add Address_is_res\n",
      "Step: score=7802.53, add 1st_update_days_ago\n",
      "Step: score=7799.38, add source_r\n",
      "Step: score=7796.08, add source_a\n",
      "Step: score=7792.91, add source_u\n",
      "Step: score=7791.19, add source_h\n",
      "Step: score=7791.19, unchanged None\n",
      "(LinearRegression(), ['Freq', 'Address_is_res', '1st_update_days_ago', 'source_r', 'source_a', 'source_u', 'source_h'])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Define Model (Linear Regression)\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = LinearRegression()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Define Scoring Metric Model (AIC Score)\\ndef score_model(model, variables):\\n    if len(variables) == 0:\\n        return AIC_score(\\n            y_train_pur, [y_train_pur.mean()] * len(y_train_pur),\\n            model, df=1\\n        )\\n    return AIC_score(y_train_pur,\\n                     model.predict(X_train_pur[variables]), model)\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(\\n    X_train_pur.columns, train_model, score_model\\n)\\nprint(best_variables)\";\n",
       "                var nbb_formatted_code = \"# Define Model (Linear Regression)\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = LinearRegression()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Define Scoring Metric Model (AIC Score)\\ndef score_model(model, variables):\\n    if len(variables) == 0:\\n        return AIC_score(\\n            y_train_pur, [y_train_pur.mean()] * len(y_train_pur), model, df=1\\n        )\\n    return AIC_score(y_train_pur, model.predict(X_train_pur[variables]), model)\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(X_train_pur.columns, train_model, score_model)\\nprint(best_variables)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Model (Linear Regression)\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_pur[variables], y_train_pur)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define Scoring Metric Model (AIC Score)\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(\n",
    "            y_train_pur, [y_train_pur.mean()] * len(y_train_pur),\n",
    "            model, df=1\n",
    "        )\n",
    "    return AIC_score(y_train_pur,\n",
    "                     model.predict(X_train_pur[variables]), model)\n",
    "\n",
    "\n",
    "# Stepwise Regression to select Best Variables\n",
    "best_variables = stepwise_selection(\n",
    "    X_train_pur.columns, train_model, score_model\n",
    ")\n",
    "print(best_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: US, source_a, source_c, source_b, source_d, source_e, source_m, source_o, source_h, source_r, source_s, source_t, source_u, source_p, source_x, source_w, Freq, last_update_days_ago, 1st_update_days_ago, Web order, Gender=male, Address_is_res\n",
      "Start: score=8123.51, constant\n",
      "Step: score=7834.90, add Freq\n",
      "Step: score=7814.55, add Address_is_res\n",
      "Step: score=7802.54, add 1st_update_days_ago\n",
      "Step: score=7799.38, add source_r\n",
      "Step: score=7796.09, add source_a\n",
      "Step: score=7792.92, add source_u\n",
      "Step: score=7791.35, add source_h\n",
      "Step: score=7791.35, unchanged None\n",
      "(Ridge(), ['Freq', 'Address_is_res', '1st_update_days_ago', 'source_r', 'source_a', 'source_u', 'source_h'])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Ridge Stepwise\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = Ridge()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Define Scoring Metric Model (AIC Score)\\ndef score_model(model, variables):\\n    if len(variables) == 0:\\n        return AIC_score(\\n            y_train_pur, [y_train_pur.mean()] * len(y_train_pur),\\n            model, df=1\\n        )\\n    return AIC_score(y_train_pur,\\n                     model.predict(X_train_pur[variables]), model)\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(\\n    X_train_pur.columns, train_model, score_model\\n)\\nprint(best_variables)\";\n",
       "                var nbb_formatted_code = \"# Ridge Stepwise\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = Ridge()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Define Scoring Metric Model (AIC Score)\\ndef score_model(model, variables):\\n    if len(variables) == 0:\\n        return AIC_score(\\n            y_train_pur, [y_train_pur.mean()] * len(y_train_pur), model, df=1\\n        )\\n    return AIC_score(y_train_pur, model.predict(X_train_pur[variables]), model)\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(X_train_pur.columns, train_model, score_model)\\nprint(best_variables)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ridge Stepwise\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = Ridge()\n",
    "    model.fit(X_train_pur[variables], y_train_pur)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define Scoring Metric Model (AIC Score)\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(\n",
    "            y_train_pur, [y_train_pur.mean()] * len(y_train_pur),\n",
    "            model, df=1\n",
    "        )\n",
    "    return AIC_score(y_train_pur,\n",
    "                     model.predict(X_train_pur[variables]), model)\n",
    "\n",
    "\n",
    "# Stepwise Regression to select Best Variables\n",
    "best_variables = stepwise_selection(\n",
    "    X_train_pur.columns, train_model, score_model\n",
    ")\n",
    "print(best_variables)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: US, source_a, source_c, source_b, source_d, source_e, source_m, source_o, source_h, source_r, source_s, source_t, source_u, source_p, source_x, source_w, Freq, last_update_days_ago, 1st_update_days_ago, Web order, Gender=male, Address_is_res\n",
      "Start: score=8123.51, constant\n",
      "Step: score=7834.92, add Freq\n",
      "Step: score=7814.72, add Address_is_res\n",
      "Step: score=7802.76, add 1st_update_days_ago\n",
      "Step: score=7799.97, add source_r\n",
      "Step: score=7796.96, add source_a\n",
      "Step: score=7794.22, add source_u\n",
      "Step: score=7794.22, unchanged None\n",
      "(Lasso(), ['Freq', 'Address_is_res', '1st_update_days_ago', 'source_r', 'source_a', 'source_u'])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Lasso Stepwise\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = Lasso()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(X_train_pur.columns,\\n                                    train_model, score_model)\\nprint(best_variables)\";\n",
       "                var nbb_formatted_code = \"# Lasso Stepwise\\ndef train_model(variables):\\n    if len(variables) == 0:\\n        return None\\n    model = Lasso()\\n    model.fit(X_train_pur[variables], y_train_pur)\\n    return model\\n\\n\\n# Stepwise Regression to select Best Variables\\nbest_variables = stepwise_selection(X_train_pur.columns, train_model, score_model)\\nprint(best_variables)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lasso Stepwise\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = Lasso()\n",
    "    model.fit(X_train_pur[variables], y_train_pur)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Stepwise Regression to select Best Variables\n",
    "best_variables = stepwise_selection(X_train_pur.columns, train_model, score_model)\n",
    "print(best_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Linear Regression Model\n",
    "_Using Best Variables from StepWise Regression_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  197.9990724045469\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Freq</td>\n",
       "      <td>142.144568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Address_is_res</td>\n",
       "      <td>-77.412058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st_update_days_ago</td>\n",
       "      <td>-31.529344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_r</td>\n",
       "      <td>71.442764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_a</td>\n",
       "      <td>47.944673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source_u</td>\n",
       "      <td>39.982971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>source_h</td>\n",
       "      <td>-154.856488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predictor  coefficient\n",
       "0                 Freq   142.144568\n",
       "1       Address_is_res   -77.412058\n",
       "2  1st_update_days_ago   -31.529344\n",
       "3             source_r    71.442764\n",
       "4             source_a    47.944673\n",
       "5             source_u    39.982971\n",
       "6             source_h  -154.856488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Linear Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 157.3888\n",
      "            Mean Absolute Error (MAE) : 98.7307\n",
      "          Mean Percentage Error (MPE) : -99.7814\n",
      "Mean Absolute Percentage Error (MAPE) : 132.0294\n",
      "\n",
      "---- Linear Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 4.1171\n",
      "       Root Mean Squared Error (RMSE) : 169.0312\n",
      "            Mean Absolute Error (MAE) : 102.8035\n",
      "          Mean Percentage Error (MPE) : -69.6319\n",
      "Mean Absolute Percentage Error (MAPE) : 101.1441\n",
      "- Metrics for using a Linear Regression -\n",
      "adjusted r2 :  0.47574557702034914\n",
      "AIC :  5257.217426473309\n",
      "BIC :  5293.140607397281\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Predictors from Linear Regression stepwise regression\\nlm_predictors = [\\n    \\\"Freq\\\",\\n    \\\"Address_is_res\\\",\\n    \\\"1st_update_days_ago\\\",\\n    \\\"source_r\\\",\\n    \\\"source_a\\\",\\n    \\\"source_u\\\",\\n    \\\"source_h\\\",\\n]\\n# Linear Regression model\\nspending_lm = LinearRegression()\\nspending_lm.fit(X_train_pur[lm_predictors], y_train_pur)\\n\\n# print coefficients\\nlist_spending_lm = pd.DataFrame(\\n    {\\n        \\\"Predictor\\\": X_train_pur[lm_predictors].columns,\\n        \\\"coefficient\\\": spending_lm.coef_,\\n    }\\n)\\nprint(\\\"intercept \\\", spending_lm.intercept_)\\ndisplay(list_spending_lm)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Linear Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur,\\n                  spending_lm.predict(X_train_pur[lm_predictors]))\\nprint(\\\"\\\\n---- Linear Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur,\\n                  spending_lm.predict(X_valid_pur[lm_predictors]))\\n\\n# calculate adjusted r2 and information criteria measures\\npred_y = spending_lm.predict(X_valid_pur[lm_predictors])\\nprint(\\\"- Metrics for using a Linear Regression -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_valid_pur,\\n                                          pred_y, spending_lm))\\nprint(\\\"AIC : \\\", AIC_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"BIC : \\\", BIC_score(y_valid_pur, pred_y, spending_lm))\";\n",
       "                var nbb_formatted_code = \"# Predictors from Linear Regression stepwise regression\\nlm_predictors = [\\n    \\\"Freq\\\",\\n    \\\"Address_is_res\\\",\\n    \\\"1st_update_days_ago\\\",\\n    \\\"source_r\\\",\\n    \\\"source_a\\\",\\n    \\\"source_u\\\",\\n    \\\"source_h\\\",\\n]\\n# Linear Regression model\\nspending_lm = LinearRegression()\\nspending_lm.fit(X_train_pur[lm_predictors], y_train_pur)\\n\\n# print coefficients\\nlist_spending_lm = pd.DataFrame(\\n    {\\n        \\\"Predictor\\\": X_train_pur[lm_predictors].columns,\\n        \\\"coefficient\\\": spending_lm.coef_,\\n    }\\n)\\nprint(\\\"intercept \\\", spending_lm.intercept_)\\ndisplay(list_spending_lm)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Linear Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, spending_lm.predict(X_train_pur[lm_predictors]))\\nprint(\\\"\\\\n---- Linear Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, spending_lm.predict(X_valid_pur[lm_predictors]))\\n\\n# calculate adjusted r2 and information criteria measures\\npred_y = spending_lm.predict(X_valid_pur[lm_predictors])\\nprint(\\\"- Metrics for using a Linear Regression -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"AIC : \\\", AIC_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"BIC : \\\", BIC_score(y_valid_pur, pred_y, spending_lm))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictors from Linear Regression stepwise regression\n",
    "lm_predictors = [\n",
    "    \"Freq\",\n",
    "    \"Address_is_res\",\n",
    "    \"1st_update_days_ago\",\n",
    "    \"source_r\",\n",
    "    \"source_a\",\n",
    "    \"source_u\",\n",
    "    \"source_h\",\n",
    "]\n",
    "# Linear Regression model\n",
    "spending_lm = LinearRegression()\n",
    "spending_lm.fit(X_train_pur[lm_predictors], y_train_pur)\n",
    "\n",
    "# print coefficients\n",
    "list_spending_lm = pd.DataFrame(\n",
    "    {\n",
    "        \"Predictor\": X_train_pur[lm_predictors].columns,\n",
    "        \"coefficient\": spending_lm.coef_,\n",
    "    }\n",
    ")\n",
    "print(\"intercept \", spending_lm.intercept_)\n",
    "display(list_spending_lm)\n",
    "\n",
    "# Regression Summary Report\n",
    "print(\"\\n---- Linear Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur,\n",
    "                  spending_lm.predict(X_train_pur[lm_predictors]))\n",
    "print(\"\\n---- Linear Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur,\n",
    "                  spending_lm.predict(X_valid_pur[lm_predictors]))\n",
    "\n",
    "# calculate adjusted r2 and information criteria measures\n",
    "pred_y = spending_lm.predict(X_valid_pur[lm_predictors])\n",
    "print(\"- Metrics for using a Linear Regression -\")\n",
    "print(\"adjusted r2 : \", adjusted_r2_score(y_valid_pur, pred_y,\n",
    "                                          spending_lm))\n",
    "print(\"AIC : \", AIC_score(y_valid_pur, pred_y, spending_lm))\n",
    "print(\"BIC : \", BIC_score(y_valid_pur, pred_y, spending_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  197.23053525276893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Freq</td>\n",
       "      <td>141.675328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Address_is_res</td>\n",
       "      <td>-81.853812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st_update_days_ago</td>\n",
       "      <td>-31.074224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source_r</td>\n",
       "      <td>73.546229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source_a</td>\n",
       "      <td>49.446687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source_u</td>\n",
       "      <td>41.456702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predictor  coefficient\n",
       "0                 Freq   141.675328\n",
       "1       Address_is_res   -81.853812\n",
       "2  1st_update_days_ago   -31.074224\n",
       "3             source_r    73.546229\n",
       "4             source_a    49.446687\n",
       "5             source_u    41.456702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Linear (Lasso Stepwise) Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0000\n",
      "       Root Mean Squared Error (RMSE) : 157.8770\n",
      "            Mean Absolute Error (MAE) : 99.2840\n",
      "          Mean Percentage Error (MPE) : -106.0743\n",
      "Mean Absolute Percentage Error (MAPE) : 136.5845\n",
      "\n",
      "---- Linear (Lasso Stepwise) Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 2.1241\n",
      "       Root Mean Squared Error (RMSE) : 167.7249\n",
      "            Mean Absolute Error (MAE) : 104.1302\n",
      "          Mean Percentage Error (MPE) : -83.9127\n",
      "Mean Absolute Percentage Error (MAPE) : 113.0084\n",
      "\n",
      "- Metrics for using a Linear (Lasso Stepwise) Regression -\n",
      "adjusted r2 :  0.48513067699034806\n",
      "AIC :  5249.010943390791\n",
      "BIC :  5280.942659767655\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Predictors from Lasso Regression stepwise regression\\nlasso_predictors = [\\n    \\\"Freq\\\",\\n    \\\"Address_is_res\\\",\\n    \\\"1st_update_days_ago\\\",\\n    \\\"source_r\\\",\\n    \\\"source_a\\\",\\n    \\\"source_u\\\",\\n]\\n# Linear Regression model\\nspending_lm = LinearRegression()\\nspending_lm.fit(X_train_pur[lasso_predictors], y_train_pur)\\n\\n# print coefficients\\nlist_spending_lm = pd.DataFrame(\\n    {\\n        \\\"Predictor\\\": X_train_pur[lasso_predictors].columns,\\n        \\\"coefficient\\\": spending_lm.coef_,\\n    }\\n)\\nprint(\\\"intercept \\\", spending_lm.intercept_)\\ndisplay(list_spending_lm)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Linear (Lasso Stepwise) Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur,\\n                  spending_lm.predict(X_train_pur[lasso_predictors]))\\nprint(\\\"\\\\n---- Linear (Lasso Stepwise) Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur,\\n                  spending_lm.predict(X_valid_pur[lasso_predictors]))\\n\\n# calculate adjusted r2 and information criteria measures\\npred_y = spending_lm.predict(X_valid_pur[lasso_predictors])\\nprint(\\\"\\\\n- Metrics for using a Linear (Lasso Stepwise) Regression -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_valid_pur, pred_y,\\n                                          spending_lm))\\nprint(\\\"AIC : \\\", AIC_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"BIC : \\\", BIC_score(y_valid_pur, pred_y, spending_lm))\";\n",
       "                var nbb_formatted_code = \"# Predictors from Lasso Regression stepwise regression\\nlasso_predictors = [\\n    \\\"Freq\\\",\\n    \\\"Address_is_res\\\",\\n    \\\"1st_update_days_ago\\\",\\n    \\\"source_r\\\",\\n    \\\"source_a\\\",\\n    \\\"source_u\\\",\\n]\\n# Linear Regression model\\nspending_lm = LinearRegression()\\nspending_lm.fit(X_train_pur[lasso_predictors], y_train_pur)\\n\\n# print coefficients\\nlist_spending_lm = pd.DataFrame(\\n    {\\n        \\\"Predictor\\\": X_train_pur[lasso_predictors].columns,\\n        \\\"coefficient\\\": spending_lm.coef_,\\n    }\\n)\\nprint(\\\"intercept \\\", spending_lm.intercept_)\\ndisplay(list_spending_lm)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Linear (Lasso Stepwise) Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, spending_lm.predict(X_train_pur[lasso_predictors]))\\nprint(\\\"\\\\n---- Linear (Lasso Stepwise) Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, spending_lm.predict(X_valid_pur[lasso_predictors]))\\n\\n# calculate adjusted r2 and information criteria measures\\npred_y = spending_lm.predict(X_valid_pur[lasso_predictors])\\nprint(\\\"\\\\n- Metrics for using a Linear (Lasso Stepwise) Regression -\\\")\\nprint(\\\"adjusted r2 : \\\", adjusted_r2_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"AIC : \\\", AIC_score(y_valid_pur, pred_y, spending_lm))\\nprint(\\\"BIC : \\\", BIC_score(y_valid_pur, pred_y, spending_lm))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictors from Lasso Regression stepwise regression\n",
    "lasso_predictors = [\n",
    "    \"Freq\",\n",
    "    \"Address_is_res\",\n",
    "    \"1st_update_days_ago\",\n",
    "    \"source_r\",\n",
    "    \"source_a\",\n",
    "    \"source_u\",\n",
    "]\n",
    "# Linear Regression model\n",
    "spending_lm = LinearRegression()\n",
    "spending_lm.fit(X_train_pur[lasso_predictors], y_train_pur)\n",
    "\n",
    "# print coefficients\n",
    "list_spending_lm = pd.DataFrame(\n",
    "    {\n",
    "        \"Predictor\": X_train_pur[lasso_predictors].columns,\n",
    "        \"coefficient\": spending_lm.coef_,\n",
    "    }\n",
    ")\n",
    "print(\"intercept \", spending_lm.intercept_)\n",
    "display(list_spending_lm)\n",
    "\n",
    "# Regression Summary Report\n",
    "print(\"\\n---- Linear (Lasso Stepwise) Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur,\n",
    "                  spending_lm.predict(X_train_pur[lasso_predictors]))\n",
    "print(\"\\n---- Linear (Lasso Stepwise) Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur,\n",
    "                  spending_lm.predict(X_valid_pur[lasso_predictors]))\n",
    "\n",
    "# calculate adjusted r2 and information criteria measures\n",
    "pred_y = spending_lm.predict(X_valid_pur[lasso_predictors])\n",
    "print(\"\\n- Metrics for using a Linear (Lasso Stepwise) Regression -\")\n",
    "print(\"adjusted r2 : \", adjusted_r2_score(y_valid_pur,\n",
    "                                          pred_y, spending_lm))\n",
    "print(\"AIC : \", AIC_score(y_valid_pur, pred_y, spending_lm))\n",
    "print(\"BIC : \", BIC_score(y_valid_pur, pred_y, spending_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Regression Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Decision Tree Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.0000\n",
      "       Root Mean Squared Error (RMSE) : 5.9231\n",
      "            Mean Absolute Error (MAE) : 0.4833\n",
      "          Mean Percentage Error (MPE) : -0.3462\n",
      "Mean Absolute Percentage Error (MAPE) : 0.5685\n",
      "\n",
      "---- Decision Tree Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -13.0375\n",
      "       Root Mean Squared Error (RMSE) : 238.9316\n",
      "            Mean Absolute Error (MAE) : 137.1975\n",
      "          Mean Percentage Error (MPE) : -116.8224\n",
      "Mean Absolute Percentage Error (MAPE) : 158.4389\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Decision Tree Regressor (No parameter tuning)\\ntree_model = DecisionTreeRegressor(random_state=1)\\ntree_model.fit(X_train_pur, y_train_pur)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Decision Tree Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, tree_model.predict(X_train_pur))\\nprint(\\\"\\\\n---- Decision Tree Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, tree_model.predict(X_valid_pur))\";\n",
       "                var nbb_formatted_code = \"# Decision Tree Regressor (No parameter tuning)\\ntree_model = DecisionTreeRegressor(random_state=1)\\ntree_model.fit(X_train_pur, y_train_pur)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Decision Tree Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, tree_model.predict(X_train_pur))\\nprint(\\\"\\\\n---- Decision Tree Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, tree_model.predict(X_valid_pur))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Tree Regressor (No parameter tuning)\n",
    "tree_model = DecisionTreeRegressor(random_state=1)\n",
    "tree_model.fit(X_train_pur, y_train_pur)\n",
    "\n",
    "# Regression Summary Report\n",
    "print(\"\\n---- Decision Tree Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur, tree_model.predict(X_train_pur))\n",
    "print(\"\\n---- Decision Tree Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur, tree_model.predict(X_valid_pur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decision Tree Regressor Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters:  {'max_depth': 10, 'max_features': 'auto', 'min_impurity_decrease': 0, 'min_samples_leaf': 1, 'min_samples_split': 50, 'min_weight_fraction_leaf': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Initital Params Search\\nparam_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"max_depth\\\": [5, 10, 15, 20, 25],\\n    \\\"min_samples_leaf\\\": [1, 3, 5],\\n    \\\"min_weight_fraction_leaf\\\": [0.0, 0.2, 0.4],\\n    \\\"min_impurity_decrease\\\": [0, 0.001, 0.005, 0.01],\\n    \\\"min_samples_split\\\": [10, 20, 30, 40, 50],\\n}\\n\\n# Grid Search for Initital Params\\ngridSearch = GridSearchCV(\\n    DecisionTreeRegressor(random_state=1), param_grid, cv=5, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Initial parameters: \\\", gridSearch.best_params_)\";\n",
       "                var nbb_formatted_code = \"# Initital Params Search\\nparam_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"max_depth\\\": [5, 10, 15, 20, 25],\\n    \\\"min_samples_leaf\\\": [1, 3, 5],\\n    \\\"min_weight_fraction_leaf\\\": [0.0, 0.2, 0.4],\\n    \\\"min_impurity_decrease\\\": [0, 0.001, 0.005, 0.01],\\n    \\\"min_samples_split\\\": [10, 20, 30, 40, 50],\\n}\\n\\n# Grid Search for Initital Params\\ngridSearch = GridSearchCV(\\n    DecisionTreeRegressor(random_state=1), param_grid, cv=5, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Initial parameters: \\\", gridSearch.best_params_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initital Params Search\n",
    "param_grid = {\n",
    "    \"max_features\": [\"None\", \"auto\", \"sqrt\"],\n",
    "    \"max_depth\": [5, 10, 15, 20, 25],\n",
    "    \"min_samples_leaf\": [1, 3, 5],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.2, 0.4],\n",
    "    \"min_impurity_decrease\": [0, 0.001, 0.005, 0.01],\n",
    "    \"min_samples_split\": [10, 20, 30, 40, 50],\n",
    "}\n",
    "\n",
    "# Grid Search for Initital Params\n",
    "gridSearch = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=1), param_grid,\n",
    "    cv=5, n_jobs=-1\n",
    ")\n",
    "gridSearch.fit(X_train_pur, y_train_pur)\n",
    "print(\"Initial parameters: \", gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved parameters:  {'max_depth': 2, 'max_features': 'auto', 'min_impurity_decrease': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "\n",
      " ---- Decision Tree Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 165.6095\n",
      "            Mean Absolute Error (MAE) : 99.5173\n",
      "          Mean Percentage Error (MPE) : -120.2848\n",
      "Mean Absolute Percentage Error (MAPE) : 144.0328\n",
      "\n",
      "---- Decision Tree  Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 6.1654\n",
      "       Root Mean Squared Error (RMSE) : 176.7016\n",
      "            Mean Absolute Error (MAE) : 102.4987\n",
      "          Mean Percentage Error (MPE) : -97.8716\n",
      "Mean Absolute Percentage Error (MAPE) : 121.1784\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Improving Parameters\\nparam_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"max_depth\\\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\\n    \\\"min_samples_leaf\\\": [1, 2, 3],\\n    \\\"min_weight_fraction_leaf\\\": [0.0, 0.05, 0.1],\\n    \\\"min_impurity_decrease\\\": [\\n        0,\\n        0.00001,\\n        0.0001,\\n        0.0005,\\n        0.001,\\n    ],\\n    \\\"min_samples_split\\\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 45, 50],\\n}\\ngridSearch = GridSearchCV(\\n    DecisionTreeRegressor(random_state=1), param_grid, cv=5, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Improved parameters: \\\", gridSearch.best_params_)\\n\\n\\n# Save best params\\nregTree = gridSearch.best_estimator_\\n\\n# Print Regression Summary\\nprint(\\\"\\\\n ---- Decision Tree Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, regTree.predict(X_train_pur))\\nprint(\\\"\\\\n---- Decision Tree  Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, regTree.predict(X_valid_pur))\";\n",
       "                var nbb_formatted_code = \"# Improving Parameters\\nparam_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"max_depth\\\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\\n    \\\"min_samples_leaf\\\": [1, 2, 3],\\n    \\\"min_weight_fraction_leaf\\\": [0.0, 0.05, 0.1],\\n    \\\"min_impurity_decrease\\\": [\\n        0,\\n        0.00001,\\n        0.0001,\\n        0.0005,\\n        0.001,\\n    ],\\n    \\\"min_samples_split\\\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 45, 50],\\n}\\ngridSearch = GridSearchCV(\\n    DecisionTreeRegressor(random_state=1), param_grid, cv=5, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Improved parameters: \\\", gridSearch.best_params_)\\n\\n\\n# Save best params\\nregTree = gridSearch.best_estimator_\\n\\n# Print Regression Summary\\nprint(\\\"\\\\n ---- Decision Tree Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, regTree.predict(X_train_pur))\\nprint(\\\"\\\\n---- Decision Tree  Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, regTree.predict(X_valid_pur))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Improving Parameters\n",
    "param_grid = {\n",
    "    \"max_features\": [\"None\", \"auto\", \"sqrt\"],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.05, 0.1],\n",
    "    \"min_impurity_decrease\": [\n",
    "        0,\n",
    "        0.00001,\n",
    "        0.0001,\n",
    "        0.0005,\n",
    "        0.001,\n",
    "    ],\n",
    "    \"min_samples_split\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 45, 50],\n",
    "}\n",
    "gridSearch = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=1),\n",
    "    param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "gridSearch.fit(X_train_pur, y_train_pur)\n",
    "print(\"Improved parameters: \", gridSearch.best_params_)\n",
    "\n",
    "\n",
    "# Save best params\n",
    "regTree = gridSearch.best_estimator_\n",
    "\n",
    "# Print Regression Summary\n",
    "print(\"\\n ---- Decision Tree Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur, regTree.predict(X_train_pur))\n",
    "print(\"\\n---- Decision Tree  Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur, regTree.predict(X_valid_pur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Random Forest Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.2126\n",
      "       Root Mean Squared Error (RMSE) : 64.2705\n",
      "            Mean Absolute Error (MAE) : 37.5195\n",
      "          Mean Percentage Error (MPE) : -43.3499\n",
      "Mean Absolute Percentage Error (MAPE) : 53.8972\n",
      "\n",
      "---- Random Forest Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.5011\n",
      "       Root Mean Squared Error (RMSE) : 166.8351\n",
      "            Mean Absolute Error (MAE) : 99.6235\n",
      "          Mean Percentage Error (MPE) : -96.3932\n",
      "Mean Absolute Percentage Error (MAPE) : 121.6811\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# Initital Random Forest Model\\n\\nrf_model = RandomForestRegressor(random_state=1)\\nrf_model.fit(X_train_pur, y_train_pur)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, rf_model.predict(X_train_pur))\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, rf_model.predict(X_valid_pur))\";\n",
       "                var nbb_formatted_code = \"# Initital Random Forest Model\\n\\nrf_model = RandomForestRegressor(random_state=1)\\nrf_model.fit(X_train_pur, y_train_pur)\\n\\n# Regression Summary Report\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, rf_model.predict(X_train_pur))\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, rf_model.predict(X_valid_pur))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initital Random Forest Model\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(X_train_pur, y_train_pur)\n",
    "\n",
    "# Regression Summary Report\n",
    "print(\"\\n---- Random Forest Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur, rf_model.predict(X_train_pur))\n",
    "print(\"\\n---- Random Forest Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur, rf_model.predict(X_valid_pur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest Regressor Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters:  {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': 'False'}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"rf_param_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"n_estimators\\\": [500, 1000, 1500],\\n    \\\"max_depth\\\": [5, 20, 50, 100],\\n    \\\"min_samples_split\\\": [2, 5, 10],\\n    \\\"min_samples_leaf\\\": [1, 2, 4],\\n    \\\"bootstrap\\\": [\\\"True\\\", \\\"False\\\"],\\n}\\n\\nrandomSearch = RandomizedSearchCV(\\n    RandomForestRegressor(random_state=1), rf_param_grid,\\n    verbose=2, cv=3, n_jobs=-1\\n)\\nrandomSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Initial parameters: \\\", randomSearch.best_params_)\";\n",
       "                var nbb_formatted_code = \"rf_param_grid = {\\n    \\\"max_features\\\": [\\\"None\\\", \\\"auto\\\", \\\"sqrt\\\"],\\n    \\\"n_estimators\\\": [500, 1000, 1500],\\n    \\\"max_depth\\\": [5, 20, 50, 100],\\n    \\\"min_samples_split\\\": [2, 5, 10],\\n    \\\"min_samples_leaf\\\": [1, 2, 4],\\n    \\\"bootstrap\\\": [\\\"True\\\", \\\"False\\\"],\\n}\\n\\nrandomSearch = RandomizedSearchCV(\\n    RandomForestRegressor(random_state=1), rf_param_grid, verbose=2, cv=3, n_jobs=-1\\n)\\nrandomSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Initial parameters: \\\", randomSearch.best_params_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    \"max_features\": [\"None\", \"auto\", \"sqrt\"],\n",
    "    \"n_estimators\": [500, 1000, 1500],\n",
    "    \"max_depth\": [5, 20, 50, 100],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [\"True\", \"False\"],\n",
    "}\n",
    "\n",
    "randomSearch = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=1), rf_param_grid, verbose=2, cv=3, n_jobs=-1\n",
    ")\n",
    "randomSearch.fit(X_train_pur, y_train_pur)\n",
    "print(\"Initial parameters: \", randomSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 381 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved parameters:  {'bootstrap': 'True', 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 3000}\n",
      "\n",
      " ---- Random Forest Regression Summary for Train Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -1.3958\n",
      "       Root Mean Squared Error (RMSE) : 94.3020\n",
      "            Mean Absolute Error (MAE) : 51.4337\n",
      "          Mean Percentage Error (MPE) : -59.4918\n",
      "Mean Absolute Percentage Error (MAPE) : 72.4183\n",
      "\n",
      "---- Random Forest Regression Summary for Validation Set ----\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.9313\n",
      "       Root Mean Squared Error (RMSE) : 165.8719\n",
      "            Mean Absolute Error (MAE) : 99.6267\n",
      "          Mean Percentage Error (MPE) : -97.2077\n",
      "Mean Absolute Percentage Error (MAPE) : 121.3139\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# Improving Params\\nrf_param_grid = {\\n    \\\"max_features\\\": [\\\"auto\\\", 1, 2, 3],\\n    \\\"n_estimators\\\": [100, 1000, 2000, 3000],\\n    \\\"max_depth\\\": [\\\"None\\\", 25, 50, 75, 90],\\n    \\\"min_samples_split\\\": [1, 2],\\n    \\\"min_samples_leaf\\\": [1, 2],\\n    \\\"bootstrap\\\": [\\\"True\\\"],\\n}\\n\\ngridSearch = GridSearchCV(\\n    RandomForestRegressor(random_state=1), rf_param_grid,\\n    verbose=2, cv=3, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Improved parameters: \\\", gridSearch.best_params_)\\n\\n\\n# Save best params\\nrf = gridSearch.best_estimator_\\n\\n# Print Regression Summary\\nprint(\\\"\\\\n ---- Random Forest Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, rf.predict(X_train_pur))\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, rf.predict(X_valid_pur))\";\n",
       "                var nbb_formatted_code = \"# Improving Params\\nrf_param_grid = {\\n    \\\"max_features\\\": [\\\"auto\\\", 1, 2, 3],\\n    \\\"n_estimators\\\": [100, 1000, 2000, 3000],\\n    \\\"max_depth\\\": [\\\"None\\\", 25, 50, 75, 90],\\n    \\\"min_samples_split\\\": [1, 2],\\n    \\\"min_samples_leaf\\\": [1, 2],\\n    \\\"bootstrap\\\": [\\\"True\\\"],\\n}\\n\\ngridSearch = GridSearchCV(\\n    RandomForestRegressor(random_state=1), rf_param_grid, verbose=2, cv=3, n_jobs=-1\\n)\\ngridSearch.fit(X_train_pur, y_train_pur)\\nprint(\\\"Improved parameters: \\\", gridSearch.best_params_)\\n\\n\\n# Save best params\\nrf = gridSearch.best_estimator_\\n\\n# Print Regression Summary\\nprint(\\\"\\\\n ---- Random Forest Regression Summary for Train Set ----\\\")\\nregressionSummary(y_train_pur, rf.predict(X_train_pur))\\nprint(\\\"\\\\n---- Random Forest Regression Summary for Validation Set ----\\\")\\nregressionSummary(y_valid_pur, rf.predict(X_valid_pur))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Improving Params\n",
    "rf_param_grid = {\n",
    "    \"max_features\": [\"auto\", 1, 2, 3],\n",
    "    \"n_estimators\": [100, 1000, 2000, 3000],\n",
    "    \"max_depth\": [\"None\", 25, 50, 75, 90],\n",
    "    \"min_samples_split\": [1, 2],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"bootstrap\": [\"True\"],\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=1),\n",
    "    rf_param_grid, verbose=2, cv=3, n_jobs=-1\n",
    ")\n",
    "gridSearch.fit(X_train_pur, y_train_pur)\n",
    "print(\"Improved parameters: \", gridSearch.best_params_)\n",
    "\n",
    "\n",
    "# Save best params\n",
    "rf = gridSearch.best_estimator_\n",
    "\n",
    "# Print Regression Summary\n",
    "print(\"\\n ---- Random Forest Regression Summary for Train Set ----\")\n",
    "regressionSummary(y_train_pur, rf.predict(X_train_pur))\n",
    "print(\"\\n---- Random Forest Regression Summary for Validation Set ----\")\n",
    "regressionSummary(y_valid_pur, rf.predict(X_valid_pur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Random Forest Regressor Feature Importance Plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# variable (feature) importance plot\\nimportances = rf.feature_importances_\\n\\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_],\\n             axis=0)\\n\\ndf = pd.DataFrame(\\n    {\\\"feature\\\": X_train_pur.columns, \\\"importance\\\": importances, \\\"std\\\": std}\\n)\\ndf = df.sort_values(\\\"importance\\\")\\nax = df.plot(kind=\\\"barh\\\", xerr=\\\"std\\\", x=\\\"feature\\\", legend=False)\\nax.set_ylabel(\\\"\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# variable (feature) importance plot\\nimportances = rf.feature_importances_\\n\\nstd = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\\n\\ndf = pd.DataFrame(\\n    {\\\"feature\\\": X_train_pur.columns, \\\"importance\\\": importances, \\\"std\\\": std}\\n)\\ndf = df.sort_values(\\\"importance\\\")\\nax = df.plot(kind=\\\"barh\\\", xerr=\\\"std\\\", x=\\\"feature\\\", legend=False)\\nax.set_ylabel(\\\"\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variable (feature) importance plot\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"feature\": X_train_pur.columns, \"importance\": importances, \"std\": std}\n",
    ")\n",
    "df = df.sort_values(\"importance\")\n",
    "ax = df.plot(kind=\"barh\", xerr=\"std\", x=\"feature\", legend=False)\n",
    "ax.set_ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature importance plot was made for the random forest model to gain further insight on what features were most important. The plot indicates that frequency (number of transactions in last year at source catalog) was the most critical factor in determining customer expected spending. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3  Choose one model on the basis of its performance on the validation data and explain your reasoning for selecting it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model (based on perfomance on the validation data): **Random Forest Regressor**\n",
    "* Regression statistic summaries on the validation were created for each model (linear regression, decision tree regressor, and random forest regressor). Based on the regression statistics, the random forest model had the lowest mean error and root mean squared error among all models used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Return to the original test data partition. Note that this test data partition includes both purchasers and nonpurchasers. Create a new data frame called Score Analysis that contains the test data portion of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"Score_Analysis = pd.DataFrame(X_test[predictors])\\nScore_Analysis[\\\"Purchase\\\"] = y_test[\\\"Purchase\\\"]\\nScore_Analysis[\\\"Spending\\\"] = y_test[\\\"Spending\\\"]\";\n",
       "                var nbb_formatted_code = \"Score_Analysis = pd.DataFrame(X_test[predictors])\\nScore_Analysis[\\\"Purchase\\\"] = y_test[\\\"Purchase\\\"]\\nScore_Analysis[\\\"Spending\\\"] = y_test[\\\"Spending\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Score_Analysis = pd.DataFrame(X_test[predictors])\n",
    "Score_Analysis[\"Purchase\"] = y_test[\"Purchase\"]\n",
    "Score_Analysis[\"Spending\"] = y_test[\"Spending\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Add a column to the data frame with the predicted scores from the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Confustion Matrix -\n",
      "Confusion Matrix (Accuracy 0.7940)\n",
      "\n",
      "              Prediction\n",
      "       Actual nonpurchasers    purchasers\n",
      "nonpurchasers           183            47\n",
      "   purchasers            56           214\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Logistic Regression on Test Data Set\\nlogit_red_pred = logit_red.predict_proba(X_test[predictors])[:, 1]\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_test[\\\"Purchase\\\"],\\n        \\\"predicted\\\": logit_red.predict(X_test[predictors]),\\n    }\\n)\\n\\n# confusion matrix\\nprint(\\\"- Confustion Matrix -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted,\\n                      class_names=classes)\";\n",
       "                var nbb_formatted_code = \"# Logistic Regression on Test Data Set\\nlogit_red_pred = logit_red.predict_proba(X_test[predictors])[:, 1]\\nred_result = pd.DataFrame(\\n    {\\n        \\\"actual\\\": y_test[\\\"Purchase\\\"],\\n        \\\"predicted\\\": logit_red.predict(X_test[predictors]),\\n    }\\n)\\n\\n# confusion matrix\\nprint(\\\"- Confustion Matrix -\\\")\\nclassificationSummary(red_result.actual, red_result.predicted, class_names=classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression on Test Data Set\n",
    "logit_red_pred = logit_red.predict_proba(X_test[predictors])[:, 1]\n",
    "red_result = pd.DataFrame(\n",
    "    {\n",
    "        \"actual\": y_test[\"Purchase\"],\n",
    "        \"predicted\": logit_red.predict(X_test[predictors]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# confusion matrix\n",
    "print(\"- Confustion Matrix -\")\n",
    "classificationSummary(red_result.actual, red_result.predicted, class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Insert Predicted Purchase and Predicted Probability Results from Logistic Regression\\nScore_Analysis[\\\"Predicted Purchase\\\"] = logit_red.predict(X_test[predictors])\\nScore_Analysis[\\\"Predicted Probability\\\"] = logit_red_pred\";\n",
       "                var nbb_formatted_code = \"# Insert Predicted Purchase and Predicted Probability Results from Logistic Regression\\nScore_Analysis[\\\"Predicted Purchase\\\"] = logit_red.predict(X_test[predictors])\\nScore_Analysis[\\\"Predicted Probability\\\"] = logit_red_pred\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert Predicted Purchase and Predicted Probability Results from Logistic Regression\n",
    "Score_Analysis[\"Predicted Purchase\"] = logit_red.predict(X_test[predictors])\n",
    "Score_Analysis[\"Predicted Probability\"] = logit_red_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Add another column with the predicted spending amount from the prediction model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Random Forest Model on Test Data Set\\nScore_Analysis[\\\"Predicted Spending\\\"] = rf.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"# Random Forest Model on Test Data Set\\nScore_Analysis[\\\"Predicted Spending\\\"] = rf.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest Model on Test Data Set\n",
    "Score_Analysis[\"Predicted Spending\"] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Add a column for “adjusted probability of purchase” by multiplying “predicted probability of purchase” by 0.107. This is to adjust for oversampling the purchasers (see earlier description). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Insert Adjusted Probability of Purchase\\nScore_Analysis[\\\"Adjusted Probability of Purchase\\\"] = (\\n    Score_Analysis[\\\"Predicted Probability\\\"] * 0.107\\n)\";\n",
       "                var nbb_formatted_code = \"# Insert Adjusted Probability of Purchase\\nScore_Analysis[\\\"Adjusted Probability of Purchase\\\"] = (\\n    Score_Analysis[\\\"Predicted Probability\\\"] * 0.107\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert Adjusted Probability of Purchase\n",
    "Score_Analysis[\"Adjusted Probability of Purchase\"] = (\n",
    "    Score_Analysis[\"Predicted Probability\"] * 0.107\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Add a column for expected spending: adjusted probability of purchase * predicted spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# Insert Expected Spending\\nScore_Analysis[\\\"Expected Spending\\\"] = (\\n    Score_Analysis[\\\"Adjusted Probability of Purchase\\\"]\\n    * Score_Analysis[\\\"Predicted Spending\\\"]\\n)\";\n",
       "                var nbb_formatted_code = \"# Insert Expected Spending\\nScore_Analysis[\\\"Expected Spending\\\"] = (\\n    Score_Analysis[\\\"Adjusted Probability of Purchase\\\"]\\n    * Score_Analysis[\\\"Predicted Spending\\\"]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert Expected Spending\n",
    "Score_Analysis[\"Expected Spending\"] = (\n",
    "    Score_Analysis[\"Adjusted Probability of Purchase\"]\n",
    "    * Score_Analysis[\"Predicted Spending\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "      <th>Predicted Purchase</th>\n",
       "      <th>Adjusted Probability of Purchase</th>\n",
       "      <th>Predicted Spending</th>\n",
       "      <th>Expected Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>159.904173</td>\n",
       "      <td>0.383937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.101505</td>\n",
       "      <td>377.821459</td>\n",
       "      <td>38.350898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060010</td>\n",
       "      <td>92.408895</td>\n",
       "      <td>5.545478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>1218.206196</td>\n",
       "      <td>130.348061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>136.799538</td>\n",
       "      <td>1.500420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044393</td>\n",
       "      <td>196.773368</td>\n",
       "      <td>8.735305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102533</td>\n",
       "      <td>270.075245</td>\n",
       "      <td>27.691497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1</td>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105451</td>\n",
       "      <td>515.357064</td>\n",
       "      <td>54.345048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>163.612844</td>\n",
       "      <td>0.392841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099409</td>\n",
       "      <td>179.243582</td>\n",
       "      <td>17.818341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Purchase  Spending  Predicted Purchase  \\\n",
       "674          0         0                   0   \n",
       "1699         1       184                   1   \n",
       "1282         0         0                   1   \n",
       "1315         1      1289                   1   \n",
       "1210         0         0                   0   \n",
       "...        ...       ...                 ...   \n",
       "537          1        44                   0   \n",
       "1450         1       281                   1   \n",
       "1919         1       514                   1   \n",
       "255          0         0                   0   \n",
       "589          1        35                   1   \n",
       "\n",
       "      Adjusted Probability of Purchase  Predicted Spending  Expected Spending  \n",
       "674                           0.002401          159.904173           0.383937  \n",
       "1699                          0.101505          377.821459          38.350898  \n",
       "1282                          0.060010           92.408895           5.545478  \n",
       "1315                          0.107000         1218.206196         130.348061  \n",
       "1210                          0.010968          136.799538           1.500420  \n",
       "...                                ...                 ...                ...  \n",
       "537                           0.044393          196.773368           8.735305  \n",
       "1450                          0.102533          270.075245          27.691497  \n",
       "1919                          0.105451          515.357064          54.345048  \n",
       "255                           0.002401          163.612844           0.392841  \n",
       "589                           0.099409          179.243582          17.818341  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"Answers = Score_Analysis[\\n    [\\n        \\\"Purchase\\\",\\n        \\\"Spending\\\",\\n        \\\"Predicted Purchase\\\",\\n        \\\"Adjusted Probability of Purchase\\\",\\n        \\\"Predicted Spending\\\",\\n        \\\"Expected Spending\\\",\\n    ]\\n]\\ndisplay(Answers)\";\n",
       "                var nbb_formatted_code = \"Answers = Score_Analysis[\\n    [\\n        \\\"Purchase\\\",\\n        \\\"Spending\\\",\\n        \\\"Predicted Purchase\\\",\\n        \\\"Adjusted Probability of Purchase\\\",\\n        \\\"Predicted Spending\\\",\\n        \\\"Expected Spending\\\",\\n    ]\\n]\\ndisplay(Answers)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Answers = Score_Analysis[\n",
    "    [\n",
    "        \"Purchase\",\n",
    "        \"Spending\",\n",
    "        \"Predicted Purchase\",\n",
    "        \"Adjusted Probability of Purchase\",\n",
    "        \"Predicted Spending\",\n",
    "        \"Expected Spending\",\n",
    "    ]\n",
    "]\n",
    "display(Answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Plot the cumulative gains chart of the expected spending (cumulative expected spending as a function of number of records targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/QElEQVR4nO3dd3hUZfbA8e9JIKH3FpqAoJDQiVTpumCF1UXBAmoQRUHXDqvurg0LNrDgoijwWxWxICgiUgQRkV5DDT0kkNBDSM/5/TEXnYVABsjkJpPzeZ555s47986cGyUn933ve15RVYwxxphzCXI7AGOMMQWfJQtjjDG5smRhjDEmV5YsjDHG5MqShTHGmFxZsjDGGJMrvyYLEXlERKJFZIOIfC4iJUSkkojMEZFtznNFr/1HikiMiGwRkV5e7W1EZL3z3lgREX/GbYwx5n/5LVmISC3gISBSVZsCwUB/YAQwT1UbAfOc14hIuPN+BNAbeF9Egp2PGwcMARo5j97+itsYY8yZiuXD55cUkQygFBAHjAS6Oe9PAhYATwF9gCmqmgbsFJEYoK2I7ALKqeoSABGZDPQFZp3ri6tUqaL16tXL27MxxpgAt3LlyoOqWvX0dr8lC1XdJyKvA3uAFOAnVf1JRKqraryzT7yIVHMOqQX87vURsU5bhrN9evsZRGQInisQ6taty4oVK/LylIwxJuCJyO6c2v3ZDVURz9VCfaAmUFpE7jjXITm06Tnaz2xUHa+qkaoaWbXqGYnRGGPMBfLnAPdVwE5VTVTVDOAboCNwQETCAJznBGf/WKCO1/G18XRbxTrbp7cbY4zJJ/5MFnuA9iJSyrl7qSewCZgBDHL2GQRMd7ZnAP1FJFRE6uMZyF7mdFkliUh753MGeh1jjDEmH/hzzGKpiHwFrAIygdXAeKAMMFVEovAklH7O/tEiMhXY6Oz/oKpmOR83FJgIlMQzsH3OwW1jjDF5SwK1RHlkZKTaALcxxpwfEVmpqpGnt9sMbmOMMbmyZGGMMSZX/p6UZ4wxRZ6qkpGlZGRlk5mlpGdlk5mdTUamkpGd/b/tzn6eh5KZlU1GtpKV7XkvK1vJzPZ+zvY8Zylxu7dTMawOj/6lCcWC8/ZawJKFMaZIUFXSMrNJTsskOS2L5PRMz3Z6FinpmaRlZpOakfXnc0Y2qZmnP2eTlpH1P88Zmc4v/tN+yZ/azszy/FL367llZXBsyVSOLfmSSt3v5qGrxlEsOPfjzoclC2NMoZSakcWB46kkJKVx6EQ6h5PTOZycxqHkdI4kp3Mo2dN2JDmdpLRMTqZnkXWev7SLBQmhxYIILR5MCefZ+3W5EsUILRZE8eAgigUHUTxYKB4URPFiQrGgIEKKBVEsSCh+6j1nv5Bgcfb/s93znhAS7BxTLMjrszyfFxwkFAsWz7Pzes3K5Txw3xD2bIxmwIDbGDt2FCWK53GmwJKFMaYAUlUST6Sx59BJdh06SdzRFPYfT2X/sVTij6Vy4Hgqh5PTczy2TGgxKpUOoWLpEKqXK0GTsHKULVGM0iHFKBUaTJnQYpQKKUaZ0GBKhRSjdGgxShYPpkTxIEo4yeDUc1535eS1xYsX06NrF8LCwvjuu++4/vrr/fZdliyMMa7IzlYOJKWy6+BJdh9KZteh/30+mZ71P/tXLh1CjfIlqFm+BK3rViCsfAlqlC9JtbKhVCodQuUyIVQsFeKXv6oLmoMHD1KlShU6dOjAK6+8wn333Ue5cuX8+p2WLIwxfqWq7DuawrYDJ9h6IImtB06wLSGJmIQT/5MQigcLdSqVol7l0rRvUIl6lUtzSeVSXFK5NDUrlCA0rzvhC6Fjx47xxBNP8PXXXxMdHU2NGjV44okn8uW7LVkYY/JMUmoGG+OOsyHuOFv2H2frgRPEJJzgRFrmH/tULRvKZdXLcEtkHS6tVob6TlKoWaEkwUG2rtnZfPfdd9x///3s37+fxx57zO9XEqezZGGMuSCHTqQRHXecDXHHiI47TvS+Y+w6dPKP96uUCaFRtbLc3LoWjaqX5bLqZbmsehkqlApxMerCJyMjg0GDBvH555/TrFkzpk+fTmTkGROs/c6ShTEmVxlZ2WyKP86q3UdYuecoq3YfYd/RlD/er1OpJE1rludvbWoTUas8ETXLUa1sCRcjDhzFixenePHiPP/88zz11FOEhLiTbC1ZGGPOcDw1g2U7DrNyzxFW7j7CutijpGZkA1CjXAnaXFKRQR0voWmt8kSElad8qeIuRxxYYmNjeeihh3jxxRcJDw9n4sSJeIpuu8eShTGGtMwsVu85ym8xB/k15iBrY4+Rla0UCxIiapVnQNu6tLmkIq3rVqRmhZJuhxuwsrOzGT9+PE8++SRZWVkMGDCA8PBw1xMFWLIwpsjakXiC+ZsTWLTtIMt2HiYlI4sggea1KzC066V0bFiZ1nUrFolbUQuCbdu2ce+997Jw4UJ69uzJ+PHjadCggdth/cGShTFFRHpmNst3HWb+5gTmb05g58FkABpULc0tkbXp1LAK7RpUpnxJ61JywyeffMKaNWuYMGECd999d4G4mvBm61kYE8ASk9JYsCXhjyuIE2mZhBQLokODyvRsUo3ul1ejTqVSbodZZK1bt47k5GQ6dOhASkoKR44coWbNmq7GdLb1LOzKwpgAk5CUyo8b9vP9uniW7zqMKlQvF8oNLcLo0bg6nRpWplSI/dN3U1paGi+99BIvv/wykZGR/Pbbb5QsWZKSJQvueJDf/o8RkcuBL7yaGgD/BCY77fWAXcAtqnrEOWYkEAVkAQ+p6mynvQ1/Lqv6A/CwBuolkTEXIDEpjR83xDNzfTxLd3oSxGXVy/Bwz0Zc1aQ6ETXLFbhujaLq999/Jyoqio0bN3LnnXfy1ltvFYr/Nv5cg3sL0BJARIKBfcA0YAQwT1VfEZERzuunRCQc6A9EADWBuSJymbMO9zhgCPA7nmTRG1uH2xRxR5LTmbk+npnr4lm68xDZCg2rleGhHo24rnkYl1Uv63aI5jS//vorXbp0oXbt2vzwww9cc801bofks/y6Fu0JbFfV3SLSB+jmtE8CFgBPAX2AKaqaBuwUkRigrYjsAsqp6hIAEZkM9MWShSmC0jKz+HlzAt+s2sfPWxLIyFIurVqaYT0acb0liAIrMTGRqlWr0rFjR0aPHs2QIUMoW7Zw/bfKr2TRH/jc2a6uqvEAqhovItWc9lp4rhxOiXXaMpzt09vPICJD8FyBULdu3TwL3hg3qSqr9hzhm1X7+H5dPMdSMqhaNpRBHerx19a1CA+zLqaC6ujRozz++ONMmzbtj8J/jz32mNthXRC/JwsRCQFuBEbmtmsObXqO9jMbVccD48FzN9R5hGlMgbPvaApfrtjLtNX72H3oJCWKB9ErogY3ta5Np0srF/i1Foq6b7/9lgceeICEhAQef/xxypcv73ZIFyU/riyuAVap6gHn9QERCXOuKsKABKc9FqjjdVxtIM5pr51DuzEBJzMrm/mbE/h82R4Wbk1EgQ4NKjO8RyN6N61BmVC7i6mgS09P54477uDLL7+kZcuWfP/997Ru3drtsC5afvyfN4A/u6AAZgCDgFec5+le7Z+JyJt4BrgbActUNUtEkkSkPbAUGAi8kw9xG5Nv9h4+yRfL9zJ1xV4SktKoVjaUB7s35JbIOjYPopAJCQmhdOnSvPTSSzzxxBMULx4Ykxz9mixEpBRwNXCfV/MrwFQRiQL2AP0AVDVaRKYCG4FM4EHnTiiAofx56+wsbHDbBICsbGXepgP83++7+TXmIAJ0u7waA9rWpfvlVa2bqRDZs2cPw4cPZ9SoUURERPDxxx8H3DiSX5OFqp4EKp/WdgjP3VE57f8S8FIO7SuApv6I0Zj8diQ5nS9W7OX/luxm39EUwsqX4OGejbglso4V6StksrOzGTduHCNGjEBV2bRpExEREQGXKMBmcBuTb6LjjjHpt11MXxNHWmY2HRpU5tnrm3BVk+p2FVEIbdmyhcGDB/Prr79y9dVXM378eOrVq+d2WH5jycIYP8rOVuZsOsBHi3awfNcRShYP5uY2tRnUoR6X1yhc99mb/zVp0iSio6OZOHEiAwcODMirCW9WSNAYP0jNyOLrVbF8tGgnOw8mU7tiSe7qWI9+kXWsqmshtmbNGk6ePEnHjh1JSUnh2LFj1KhRw+2w8pQVEjQmHxw9mc7kJbuZ9NsuDiWn07x2ed69rRW9I2pYV1MhlpqaygsvvMCrr75K27ZtWbx4cYEv/JfXLFkYkwcOJ6fz4aIdTP5tF8npWXS/vCpDulxK+waVAr57ItAtXryYqKgotmzZwqBBg3jzzTeL5H9TSxbGXISDJ9L48Jcd/N/vu0nJyOK6ZmEM69GQxjXKuR2ayQOLFi2ia9eu1KlThx9//JFevXq5HZJrLFkYcwESklIZv3AH/126m/TMbG5oUZPhPRrSsJoNWgeCAwcOUL16dTp16sQbb7zB4MGDC13hv7xmycKY83DgeCofLNzOZ0v3kJGVTd9WtXiwe0MurVrG7dBMHjh8+DCPPfYY06dPJzo6mrCwMB555BG3wyoQLFkY44PEpDTe+zmGz5btIStbuclJEvWqlHY7NJNHvv76ax588EEOHjzIiBEjqFixotshFSiWLIw5h2MpGXz4yw4+XryTtMxs/ta6Ng92b0jdylavKVCkp6dz22238fXXX9OqVSt+/PFHWrZs6XZYBY4lC2NycDI9k4m/7eKDBds5nprJDS1q8shVjWhg3U0BJyQkhPLly/Pyyy/z+OOPU6yY/VrMif1UjPGSnpnN58v28M78GA6eSKNn42o8+pfLiKhZuNciMP9r165dDB8+nJdffpmmTZsyYcIEt0Mq8CxZGIOnAuy01ft4e+5WYo+k0K5+Jf5zZ2vaXFLJ7dBMHsrOzua9995j5MiRiAhbtmyhaVOrUeoLSxamSFNV5m5K4NUfNxOTcIJmtcoz6q/N6NyoSpGceBXINm/ezODBg1m8eDG9evXiP//5D5dcconbYRUalixMkbUx7jgvztzIb9sP0aBqacbd3preTWtYkghQkydPZtOmTUyaNIk777zT/jufJyskaIqchKRU3vxpK1+s2Ev5ksV55KrLuK1dXYpb7aaAs2rVKlJSUujUqROpqakcO3aM6tWrux1WgWaFBE2Rl5aZxYRfd/Le/BjSMrO5p1N9HurRiPKlrApsoElJSeH5559n9OjRfxT+K1GiBCVKlHA7tELL38uqVgA+wrPKnQL3AFuAL4B6wC7gFlU94uw/EogCsoCHVHW2096GP5dV/QF4WAP1ksj4xYItCTz33UZ2HkzmqibVefq6JtS3CXUBadGiRQwePJitW7cSFRXF6NGjrcspD/j7unsM8KOqNgZaAJuAEcA8VW0EzHNeIyLhQH8gAugNvC8iwc7njAOGAI2cR28/x20CxN7DJ7l38gru+mQ5Aky6py0fDYq0RBGgFi1aRJcuXUhPT2fOnDl89NFHNhM7j/jtykJEygFdgLsAVDUdSBeRPkA3Z7dJwALgKaAPMEVV04CdIhIDtBWRXUA5VV3ifO5koC8wy1+xm8IvNSOLDxZuZ9yC7QQHCU/1bkzUlfUJKWbjEoFo//791KhRg06dOjFmzBiioqIoXdr+IMhL/vyX0wBIBD4RkdUi8pGIlAaqq2o8gPNczdm/FrDX6/hYp62Ws316+xlEZIiIrBCRFYmJiXl7NqZQUFXmbDzA1W8t5O2527g6vDrzHuvK0G6XWqIIQIcOHWLQoEE0adKE+Ph4goKCeOihhyxR+IE/xyyKAa2B4aq6VETG4HQ5nUVOnYp6jvYzG1XHA+PBczfU+YVrCrudB5N57rtoFmxJpFG1Mnx2bzs6XlrF7bCMH6gqX331FcOGDePw4cOMHDmSSpVsAqU/+TNZxAKxqrrUef0VnmRxQETCVDVeRMKABK/963gdXxuIc9pr59BuDOAp0fHBwu28Oz+GkGJBPHNdEwZ1rGe3wgao9PR0+vfvz7Rp02jTpg0//fQTLVq0cDusgOe3f02quh/YKyKXO009gY3ADGCQ0zYImO5szwD6i0ioiNTHM5C9zOmqShKR9uK5pWGg1zGmiFu5+zDXjV3Em3O28peI6sx/rCuDOzewRBHAQkJCqFy5Mq+99hq///67JYp84u95FsOBT0UkBNgB3I0nQU0VkShgD9APQFWjRWQqnoSSCTyoqlnO5wzlz1tnZ2GD20Xe8dQMXvtxM58u3UPN8iX5+K5IejS2yVaBaseOHQwbNoxXX32VZs2a8eGHH7odUpHj12ShqmuAM2YC4rnKyGn/l4CXcmhfgWeuhjH8uGE//5qxgcSkNO7uWJ/H/nIZpUNtfmkgysrK4p133uHpp58mODiYmJgYmjVr5nZYRZL9CzOFRsLxVJ6dvoHZ0QdoElaO8XdG0qJOBbfDMn4SHR1NVFQUS5cu5brrruODDz6gdu3auR9o/MKShSnwVJVv1+zj3zM2kpqRxVO9GzO4c30blwhwn332GTExMXz66acMGDDAZmG7zAoJmgItISmVp6dtYM7GA7S5pCKj/9bcVqsLYCtWrCA1NZUrr7yS1NRUjh8/TrVq1XI/0OSZsxUSzPVPMxHpJyJlne1nROQbEWntjyCNOUVVmb5mH3956xcWbk3k6WubMPW+DpYoAlRKSgpPPvkk7dq1Y8QIz3SsEiVKWKIoQHzphnpWVb8UkSuBXsDreGo1tfNrZKbIOngijWembeDH6P20rFOB1/u1oGE1SxKBauHChQwePJiYmBjuvfdeRo8e7XZIJge+JItTt69eB4xT1eki8m//hWSKsoVbE3ls6lqOp2Yw4prG3Nu5AcFB1lcdqBYtWkS3bt1o0KAB8+bNo0ePHm6HZM7Cl2SxT0T+A1wFvCoiofi/Wq0pYtIys3h11hY+XryTy6uX5b+D29K4Rjm3wzJ+EhcXR82aNenUqRPvvPMOd999t9VzKuB8+aV/CzAb6K2qR4FKwBP+DMoULdsOJNH3vd/4ePFOBnW4hOnDOlmiCFCJiYncfvvthIeHExcXR1BQEMOGDbNEUQjkemWhqidFZDpQXUTqOs2b/RuWKQpUlf8u3cOL32+kTGgxm4UdwFSVL774guHDh3Ps2DGefvppqlSxIo+FSa7JQkSGA/8CDgDZTrMCzf0Ylwlwx1MzePLLdfwYvZ+ul1VldL/mVCtrS14GovT0dPr168eMGTNo27YtEyZMoGlTK8hQ2PgyZvEwcLmqHvJ3MKZoiI47xgOfrmLfkRSeua4J93SqT5ANYgeskJAQwsLCeOONN3j44YcJDg7O/SBT4PgyZrEXOObvQEzgU1WmLNvDX9//jbSMbL64rz2DOzewRBGAtm/fTq9evVi/fj0AH3zwAY8++qglikLMlyuLHcACEZkJpJ1qVNU3/RaVCTgp6Vk88+0Gvl4VS+dGVXj71pZULhPqdlgmj2VlZTFmzBieeeYZihcvzvbt263wX4DwJVnscR4hzsOY87I98QQP/HcVWxOS+PtVjRjeo5HNnQhAGzZsICoqimXLlnHDDTcwbtw4atXKcQVkUwj5cjfUc/kRiAlM362NY8TX6wgtHszke9rSuVFVt0MyfjJlyhR27NjB559/zq233mqF/wLMWQsJisjbqvp3EfmOHNa8VtUb/R3cxbBCgu7KylZembWJDxftpM0lFXn3tlaElS/pdlgmjy1btozU1FS6dOlCamoqSUlJVK1qfxAUZmcrJHiuK4v/c55f909IJlAlp2Xy8JQ1zN10gIEdLuHZ68OtnHiAOXnyJM8++yxvv/02HTp04Ndff6VEiRKUKGG3PweqsyYLVV3pPC+80A8XkV1AEp76UpmqGikilYAvgHrALuAWVT3i7D8SiHL2f0hVZzvtbfhzWdUfgIc1UGurF3Lxx1KImriCzfuP89yNEQzqWM/tkEwemz9/Pvfeey87duzg/vvv59VXX3U7JJMPfClR3khEvhKRjSKy49TjPL6ju6q29LqsGQHMU9VGwDznNSISDvQHIoDewPsicuo+u3HAEKCR8+h9Ht9v8sm62KP0eXcxew6f5OO7rrBEEYAWLlxIz549CQoKYsGCBYwbN45y5aw0S1HgS9/AJ3h+WWcC3YHJ/NlFdSH6AJOc7UlAX6/2Kaqapqo7gRigrYiEAeVUdYlzNTHZ6xhTQMxaH88t/1lCSLEgvh7akW6X2zoEgWTfvn0AdO7cmffff59169bRtWtXl6My+cmXZFFSVefhGQzfrar/BnytI6zATyKyUkSGOG3VVTUewHk+9VulFp4JgKfEOm21nO3T288gIkNEZIWIrEhMTPQxRHOxPlm8kwc+W0V4WDm+fbATl9co63ZIJo8kJiYyYMAAIiIi/ij8N3ToUEqWtJsVihpf5lmkikgQsE1EhgH7+PMXfG46qWqciFQD5ojIuQoQ5nSfnZ6j/cxG1fHAePDcDeVjjOYCqSqvzd7CuAXb6RVRnTH9W1GiuM3QDQSqymeffcbDDz9MUlISzz77rBX+K+J8SRZ/B0oBDwEv4LmqGOTLh6tqnPOcICLTgLbAAREJU9V4p4spwdk9FqjjdXhtIM5pr51Du3FRRlY2T329jm9W7eO2dnV5oU9Tm2gXINLT07npppuYOXMm7du3Z8KECYSHh7sdlnFZrt1QqrpcVU+oaqyq3q2qN6nq77kdJyKlvdbuLg38BdgAzODPZDMImO5szwD6i0ioiNTHM5C9zOmqShKR9uKZ5TPQ6xjjgpPpmdw7eQXfrNrHo1dfxkt9LVEEkpCQEOrUqcNbb73Fr7/+aonCAL6VKM9pUt4xYAXwH1VNPcuh1YFpzizOYsBnqvqjiCwHpopIFJ4yIv0AVDVaRKYCG/EMpj+oqqeWdB3Kn7fOznIexgVHT6Zz1yfLWRd7lJdvasaAtnVzP8gUeNu2bWPo0KG8+eabNG/enHHjxrkdkilgfC0kWBX43Hl9K561LS4DPgTuzOkgVd0BtMih/RDQ8yzHvAS8lEP7CsAK4LssMSmNOycsZUdiMuPuaEOviBpuh2QuUmZmJm+++Sb/+te/CA0NZdeuXTRvbkvVmDP5kixaqWoXr9fficgvqtpFRKL9FZgpWOKOpnDHR0uJP5bKhLsircZTAFi7di1RUVGsXLmSvn378t5771GzZk23wzIFlC/JoqqI1FXVPQDO0qqnbotI91tkpsDYdTCZ2z9ayvGUDCZHteWKepXcDsnkga+++oq9e/cydepU/va3v1nhP3NOZy0k+McOItcCHwDb8dzGWh94AFgA3Kuqb/s3xAtjhQTzxvbEEwwY/zsZWdlMvqcdzWqXdzskcxGWLFlCRkYGXbp0IS0tjRMnTlC5cmW3wzIFyIUUEgRAVX8QkUZAYzzJYrPXoPbbeRqlKVBOJYpsVb64rwOXVbfJdoVVcnIyTz/9NGPHjuXKK6/kl19+ITQ0lNBQW4DK+ManUqBOCY61qrrmHHc/mQCyw0kUWdnKZ/e2t0RRiM2dO5emTZsyZswYHnjgAWbOnOl2SKYQ8mXMwhQxOw8mM+BDSxSBYOHChVx99dU0atSIX375hc6dO7sdkimkbJEB8z92HUx2xiiUT+9tZ3WeCqm9ez1l1rp06cIHH3zA2rVrLVGYi+JLiXIRkTtE5J/O67oi0tb/oZn8Fnc0hQEf/k5aZhafDm5H4xpWerqw2b9/P/369aNp06bExcUhItx3331W+M9cNF+uLN4HOgADnNdJwHt+i8i44khyOgM/XsaJ1Ez+O7gdTcIsURQmqsrkyZMJDw/nu+++Y8SIEba8qclTvoxZtFPV1iKyGkBVj4hIiJ/jMvnoZHom90xazp7DJ5l0d1siatrtsYVJeno6ffr04ccff6Rjx45MmDCBxo0bux2WCTC+XFlkOCvWKYCIVAWy/RqVyTcZWdk88Okq1u49ytj+Lelwqd1zX9iEhIRw6aWX8s4777Bo0SJLFMYvfEkWY4FpQDUReQn4FRjl16hMvlBV/vHNehZsSeTFvs3o3TTM7ZCMj7Zs2UKPHj1Ys2YNAO+++y7Dhg0jKMjuWTH+4UuJ8k+BJ4GXgXigr6p+6e/AjP+NW7idL1fG8lCPhtzWzqrHFgaZmZm88sortGjRgtWrV/9x15Mx/uZLifIxwBeqaoPaAeSH9fG89uMWbmhRk0euvsztcIwP1qxZQ1RUFKtWreLmm2/m3XffpUYNq/xr8ocvA9yrgGdE5DI83VFfOCXDTSG1Zu9RHvliDa3rVmD035pbAblC4ptvvmHfvn189dVX3HzzzW6HY4qYXAsJ/rGjSCXgZqA/UFdVG/kzsItlhQRztu9oCn3eXUyJ4kF8+2AnqpSx2kAF2eLFi8nIyKBbt26kpaWRnJxMpUpW9df4z9kKCZ7PaFhDPMUE6wGbz+OLg0VktYh877yuJCJzRGSb81zRa9+RIhIjIltEpJdXexsRWe+8N1bsT+ELcjI9k6iJy0nLyOKTu66wRFGAJSUlMXz4cDp37sw///lPAEJDQy1RGNf4MoP7VRHZBjwPRANtVPWG8/iOh4FNXq9HAPOcK5N5zmtEJBzPVUsE0Bt437llF2AcMATPutyNnPfNeVBVnvhyHVsPJPHu7a1pZPWeCqzZs2fTtGlT3nvvPYYPH84PP/zgdkjG+HRlsRPooKq9VfVjVT3q64eLSG3gOuAjr+Y+wCRnexLQ16t9ilPhdicQA7QVkTCgnKouUU+f2WSvY4yP3l+wnZnr43mqd2O6XmYzewuqBQsW0Lt3b0qVKsWvv/7KmDFjKFOmjNthGXP2ZCEip2b2LAPqikhr74ePn/82nttuvSfxVVfVeADnuZrTXgvwvg8w1mmr5Wyf3m58NH/zAV7/aQs3tqjJkC4N3A7H5GD37t0AdO3alQ8//JDVq1fTsWNHl6My5k/nuhvqUTxdP2/k8J4CPc71wSJyPZCgqitFpJsPseQ0DqHnaM/pO4fgiZm6dW3eAHgWMHr48zWEh5Xj1ZvtzqeCJj4+nmHDhjF37lw2btxIrVq1GDx4sNthGXOGsyYLVR3ibF5z+oJHIlLCh8/uBNzoLMtaAignIv8FDohImKrGO11MCc7+sUAdr+NrA3FOe+0c2nOKeTwwHjx3Q/kQY0A7nprBvZNXEFIsiPEDIykZEpz7QSZfqCqTJk3ikUceISUlheeee47q1au7HZYxZ+XLmMVvPrb9D1Udqaq1VbUenoHr+ap6BzADGOTsNgiY7mzPAPqLSKiI1MczkL3M6apKEpH2zl1QA72OMWeRna08MmUNew6d5P3bW1OrgpWoLijS09Pp3bs3d999N82aNWPt2rU89dRTFCtma5GZguus/3eKSA08YwMlRaQVf3YHlQNKXcR3vgJMFZEoYA/QD0BVo0VkKrARyAQeVNUs55ihwESgJDDLeZhzeGd+DPM2J/BCnwjaNbDigAVJSEgIl112GX369OH++++3ek6mUDjrpDwRGQTcBUQC3rPbkoCJqvqN36O7CEV5Ut7imIPcMWEpf21Vizf6tbBxigJg06ZN3H///YwZM4aWLVu6HY4xZ3Xek/JUdZKqdgfuUtXuXo8bC3qiKMoOHE/l4SmraVi1DC/2bWqJwmUZGRm89NJLtGzZkg0bNrBv3z63QzLmguTaSaqqX4vIdXgmy5Xwan/en4GZ85eZlc3wz1eTnJbFlCGtKRVifeBuWrVqFffccw9r167llltu4Z133qFatWq5H2hMAeRL1dkP8IxRdMczue5veOZemALmjTlbWbbzMG/d2oKG1WyGtttmzJhBQkIC06ZNo2/fvm6HY8xFybWQoIisU9XmXs9lgG9U9S/5E+KFKWpjFvM3H+CeiSsY0LYuL9/UzO1wiqxFixaRmZlJ9+7dSU9PJzk5mYoVK+Z+oDEFxMUUEkxxnk+KSE0gA6ifl8GZixN75CSPfLGW8LBy/OuGcLfDKZKOHz/Ogw8+SJcuXXjuuecAz11PlihMoPAlWXwvIhWA0XjWttgFTPFjTOY8pGdmM+yz1WRnK+/f3poSxW3iXX6bNWsWTZs2Zdy4cfz9739n5syZbodkTJ7zZYD7BWfza6fMeAlVPebfsIyvXp61iTV7jzLu9tbUq1La7XCKnAULFnDttdcSHh7Ob7/9Rvv27d0OyRi/ONekvJvO8R52+6z75m48wCeLd3FXx3pc0yzM7XCKDFVl165d1K9fn65duzJhwgRuv/12QkNtfRATuM51ZXGuNSsUsGThogPHU3niq7VE1CzHyGsb536AyRNxcXE88MADzJ8/n02bNlGrVi3uuecet8Myxu/OVUjw7vwMxPguO1t5dOoaUjOyGTugFaHFbJzC31SVjz/+mMcee4y0tDReeOEFK/xnihRf5ln8M6d2m5TnnvGLdrA45hCv3NSMS6vawjj+lp6ezrXXXsu8efPo2rUrH330EQ0bNnQ7LGPylS9TfJO9tksA1/O/y6SafLR271Fen72Fa5vV4NYr6uR+gLlgqoqIEBISQtOmTenXrx/33nuvFf4zRVKuk/LOOEAkFJihqr38E1LeCMRJeSfSMrlu7CIyMrOZ9XAXypcq7nZIASs6Opr777+fsWPH0qpVK7fDMSbfXMykvNOVAmxtThf8a3o0ew+f5O3+rSxR+El6ejovvPACrVq1YtOmTezfv9/tkIwpEHwZs1jPn8uYBgNVARuvyGcz1sbx9apYHurRkLb1K7kdTkBavnw5UVFRrF+/nv79+zN27FiqVq3qdljGFAi+jFlc77WdCRxQ1Uw/xWNysP9YKs9MW0/LOhV4qGcjt8MJWDNnzuTQoUNMnz6dG2+80e1wjClQfBqzEJGKeNbH/iO5qOoqP8Z10QJlzEJVGfjxMlbsOsIPD3emvs3SzlMLFiwgKyuLnj17kp6eTkpKCuXLl3c7LGNcc8FjFiLyArAOGAu84Txe9+G4EiKyTETWiki0iDzntFcSkTkiss15ruh1zEgRiRGRLSLSy6u9jYisd94bK0VoRZ//Lt3Dom0H+ce1jS1R5KFjx45x//330717d1588UXAU/jPEoUxOfNlgPsW4FJV7ea1Wl4PH45LA3qoagugJdBbRNoDI4B5qtoImOe8RkTCgf54FlnqDbwvIqdmm40DhgCNnEdvX0+wMNt5MJlRMzfRuVEV7mh/idvhBIzvv/+eiIgIPvzwQx5//HEr/GeMD3xJFhuACuf7wepxwnlZ3Hko0AeY5LRPAvo6232AKaqapqo7gRigrYiEAeVUdYl6+swmex0TsDKzsnls6hqKBwuv/a25LY+aR37++WduuOEGKlasyJIlSxg9ejSlSpVyOyxjCjxfBrhfBlaLyAY8VwsAqGquI4DOlcFKoCHwnqouFZHqqhrvfEa8iJxaZ7IW8LvX4bFOW4azfXp7Tt83BM8VCHXr1vXh1Aqu//yyg1V7jjKmf0vCypd0O5xCTVXZsWMHl156Kd26dWPixIkMGDCAkJAQt0MzptDwJVlMAl4F1gPZ5/PhqpoFtHTWw5gmIk3PsXtOfzrrOdpz+r7xwHjwDHCfT6wFSXTcMd6eu5XrmodxY4uabodTqMXGxjJ06FAWLlz4R+G/QYMGuR2WMYWOL8nioKqOvZgvUdWjIrIAz1jDAREJc64qwoAEZ7dYPHdcnVIbiHPaa+fQHpDSMrN4bOpaKpQK4cU+Ta376QJlZ2fz0Ucf8cQTT5CRkcFLL71EjRo13A7LmELLlzGLlSLysoh0EJHWpx65HSQiVZ0rCkSkJHAVsBmYAZz6024QMN3ZngH0F5FQEamPZyB7mdNllSQi7Z27oAZ6HRNw3vt5O5v3J/HKTc2oWNq6SS5EWloaV111Fffddx9t2rRh/fr1PPLIIwQHW3VeYy6UL1cWpwrjeC8BpkBud0SFAZOccYsgYKqqfi8iS4CpIhIF7AH6AahqtIhMBTbimfz3oNONBTAUmAiUBGY5j4CzKf447/8cw19b1aJnEyt/fb5OFf4LDQ2lRYsWDBgwgMGDB9vVmTF54LwLCRYWhW1SXmZWNn99/zfij6Uw55GudlVxntavX899993Hu+++S+vWuV74GmPO4myT8mw9iwLiw0U7Wb/vGO/f3toSxXlIS0tj1KhRjBo1iooVK5KYmOh2SMYEJFvPogDYnniCt+ZupXdEDa61tbR9tnTpUqKiooiOjuaOO+7grbfeokqVKm6HZUxAyjVZqOob3q9F5HU8g9EmD2RlK09+tY6SxYN5vm+E2+EUKrNnz+bYsWN8//33XHfddW6HY0xAs/UsXDZ5yS5W7j7Cv24Ip1rZEm6HU+DNnz+fuXPnAjBixAiio6MtURiTD3wpJLheRNY5j2hgCzDG/6EFvr2HT/Laj1vodnlV/toqx0npxnH06FHuvfdeevbsyahRowBP4b9y5cq5HJkxRYOtZ+ESVeXpbzcQJDDqr83s9s5zmDFjBkOHDmX//v08+eST/Pvf/3Y7JGOKHF+SRRgQrapJACJSRkQiVHWpf0MLbN+vi+eXrYn8+4Zwalaw2k9n8/PPP9OnTx+aN2/O9OnTiYw8444+Y0w+8GXMYhxwwuv1SafNXKBjKRk8991Gmtcuz50d6rkdToGjqsTExADQrVs3Jk+ezPLlyy1RGOMiX5KFqNfMPVXNxrcrEnMWo2dv5nByGqP+2ozgIOt+8rZ3716uv/56WrVqxb59+xAR7rzzTqsQa4zLfEkWO0TkIREp7jweBnb4O7BAtWrPET5duoe7OtanaS1ble2U7Oxsxo0bR0REBAsWLODFF1+0wn/GFCC+XCHcj2dJ1Wfw1ISah7NmhDk/GVnZ/OOb9dQoV4JH/3KZ2+EUGGlpafTq1YuFCxdy1VVXMX78eOrXr+92WMYYL75MykvAs9ypuUifLN7J5v1JfHBHG8qEWk+ed+G/Nm3aMGjQIO666y67M8yYAuhCJuWZC5CQlMqYudvo2bgavSKsouzatWvp0KEDK1euBOCNN97g7rvvtkRhTAFlySKfvDF7K+lZ2TxzfXiR/oWYlpbGs88+S2RkJDt37uTQoUNuh2SM8YH1heSDDfuOMXXlXgZfWZ/6VUq7HY5rlixZQlRUFJs2bWLgwIG8+eabVK5c2e2wjDE+8KXcxzNe26H+DSfwqCrPf7+RiqVCGNajkdvhuGrOnDkkJycza9YsJk2aZInCmELkrMlCRJ4UkQ7A37yal/g/pMDy44b9LNt5mEevvozyJYu7HU6+mzt3LnPmzAE8hf82bNhA7969XY7KGHO+znVlsQXPkqcNRGSRiIwHKovI5b58sIjUEZGfRWSTiEQ78zMQkUoiMkdEtjnPFb2OGSkiMSKyRUR6ebW3cQoaxojIWCkknf6pGVmMmrWJxjXK0v+KOm6Hk6+OHDlCVFQUV199Na+88grgKfxXtmxZlyMzxlyIcyWLI8A/gBigG565FgAjROQ3Hz47E3hMVZvgWb/7QREJB0YA81S1EZ45GyMAnPf6AxFAb+B9Z/1u8JQXGQI0ch6F4k/TyUt2sfdwCs9cF06x4KJzL8E333xDeHg4kyZNYuTIkcycOdPtkIwxF+lcv8F6AzOBS4E3gbZAsqreraodc/tgVY1X1VXOdhKe1fVqAX2ASc5uk4C+znYfYIqqpqnqTjxJqq2IhAHlVHWJU3ZkstcxBdaxkxm89/N2ul1elSsbFZ3V2+bPn8/NN99MjRo1WL58OaNGjaJECVunw5jC7qzJQlX/oao9gV3Af/HcOVVVRH4Vke/O50tEpB7QClgKVFfVeOc74oFqzm61gL1eh8U6bbWc7dPbc/qeISKyQkRWuL0W87iF2zmemsGTvRq7Gkd+UFW2bt0KQPfu3fn0009ZtmwZrVq1cjkyY0xe8aVvZLaqLlfV8UCsql4J3O3rF4hIGeBr4O+qevxcu+bQpudoP7NRdbyqRqpqZNWqVX0NMc/FH0vhk8U76duyFuE1A3txnt27d3PNNdfQpk2bPwr/3XbbbRQvXvQG840JZLkmC1V90uvlXU7bQV8+XESK40kUn6rqN07zAadrCec5wWmPBbxHgWsDcU577RzaC6wxc7ehCo9eHbj1n7Kzs3n33XeJiIjg119/5eWXXyYsLMztsIwxfnJeo66qutbXfZ07liYAm1T1Ta+3ZgCDnO1BwHSv9v4iEioi9fEMZC9zuqqSRKS985kDvY4pcGISkpi6Yi+3t69LnUql3A7HL9LS0ujatSvDhw+nU6dOREdHM2zYMIKCis4gvjFFjT9ncHcC7gTWi8gap+0fwCvAVBGJAvbguT0XVY0WkanARjx3Uj2oqlnOcUOBiUBJYJbzKJBe+3ELpUKKMax7Q7dDyXPehf/at2/P4MGDGThwYJEuX2JMUSFe6xoFlMjISF2xYkW+fufK3Ye5edwSHrv6Mob3DKzZ2qtXr+a+++5j3LhxtGnTxu1wjDF+IiIrVfWMZSmt3yCPqCqvztpClTKhRHUOnLUYUlNT+cc//sEVV1zBnj17OHz4sNshGWNcYMkijyzYmsiyXYd5uGdDSoUERn3GxYsX07JlS15++WUGDhzIpk2buPrqq90OyxjjgsD4reYyVWXM3G3UqlCSW6+o63Y4eebnn38mLS2Nn376yZKEMUWcXVnkgV+2HWTN3qM80P1SQooV7h/p7Nmz+emnnwB46qmnWL9+vSUKY4wli4vluarYSs3yJejXpvAWCzx8+DCDBg2id+/evPbaawAUL16cMmXKuByZMaYgsGRxkRbHHGLVnqMM7d6w0F5VfPXVVzRp0oTPPvuMp59+mu+//97tkIwxBYyNWVwEVWXMvK2ElS/BLZG1cz+gAJo/fz79+vWjdevWzJ49m5YtW7odkjGmACqcfwoXEMt2Hmb5riMM7XYpocWCcz+ggFBVNm/eDHgK/33++ecsXbrUEoUx5qwsWVyEib/tokKp4twSWXjGKnbt2kWvXr2IjIwkNjYWEaF///4UK2YXmcaYs7NkcYHijqbw08YD3HpFHUoUL/hXFVlZWYwdO5amTZuyZMkSRo8eTc2aNd0OyxhTSNifkxfo06W7UVXuaHeJ26HkKi0tjR49evDbb79xzTXX8MEHH1C3buDMBzHG+J9dWVyA1IwsPl+2l55NqhfoyrKn6n6FhobSuXNn/u///o+ZM2daojDGnDdLFhdg5rp4DienM6hDPbdDOauVK1cSGRnJqWKKr7zyCnfccYdViDXGXBBLFhfgv0t306BqaTo1rOx2KGdISUlhxIgRtGvXjvj4eI4dO+Z2SMaYAGDJ4jxtO5DE6j1HGXBF3QL3V/ovv/xCixYtePXVV7n77rvZuHEjPXv2dDssY0wAsAHu8/TlyliKBQl9W9VyO5Qz/PLLL2RmZjJ37lxLEsaYPGVXFuchIyubb1bF0qNxNaqWDXU7HAB++OEHZs+eDfxZ+M8ShTEmr/ktWYjIxyKSICIbvNoqicgcEdnmPFf0em+kiMSIyBYR6eXV3kZE1jvvjRUX+35+3pzAwRPpBWIS3sGDB7nzzju57rrreOONNwBP4b/SpUu7HJkxJhD588piItD7tLYRwDxVbQTMc14jIuFAfyDCOeZ9ETk1020cMARo5DxO/8x8M3VFLFXLhtLt8qpuhYCq8sUXXxAeHs6UKVN49tln+e6771yLxxhTNPgtWajqL8Dpa3D2ASY525OAvl7tU1Q1TVV3AjFAWxEJA8qp6hL1TBqY7HVMvkpMSuPnLQnc1LoWxYLd672bP38+/fv3p27duqxcuZLnn3+e0NCC0SVmjAlc+f1br7qqxgM4z9Wc9lrAXq/9Yp22Ws726e05EpEhIrJCRFYkJibmaeDfr4sjK1v5W+v8ry6rqmzcuBGAHj16MGXKFH7//XeaN2+e77EYY4qmgjLAndM4hJ6jPUeqOl5VI1U1smrVvO0q+nZNHOFh5WhUvWyefm5uduzYwVVXXUXbtm3Zt28fIsKtt95qhf+MMfkqv5PFAadrCec5wWmPBbxHjWsDcU577Rza89Wug8ms3XuUvq3yr/BeVlYWb731Fk2bNmX58uW8+eabhIWF5dv3G2OMt/xOFjOAQc72IGC6V3t/EQkVkfp4BrKXOV1VSSLS3rkLaqDXMflm+po4ROCGFvmTLNLS0rjyyit59NFH6dGjBxs3bmTIkCEEBRWUC0FjTFHjt74MEfkc6AZUEZFY4F/AK8BUEYkC9gD9AFQ1WkSmAhuBTOBBVc1yPmoonjurSgKznEe+UVWmr9lHu/qVCCtf0u/fJSKEhobSrVs3hg8fzoABAwrcTHFjTNEjpyqTBprIyEg9VUTvYqyLPcqN7y7mlZua0b+t/6q1Ll++nCFDhjB+/HiuuOIKv32PMcaci4isVNXI09utXyMX09fEERIcxDVN/TNecPLkSZ544gnat29PYmIiJ06c8Mv3GGPMxbBkcQ5Z2cp3a+PodnlVypcqnuefv3DhQlq0aMHrr7/O4MGDiY6Opnv37nn+PcYYc7Hs/stzWLP3CAlJaX4b2F68eDGqyvz58y1JGGMKNLuyOIelOz0T0DtemnfrVnz33XfMmuUZo3/iiSdYt26dJQpjTIFnyeIclu88TMNqZahc5uLLaSQmJnLbbbdx44038vbbbwOewn+lShXcZVmNMeYUSxZnkZWtrNh1hLb1K13U56gqn332GU2aNOGrr77iueees8J/xphCx8YszmLz/uMkpWXStt7FJYv58+dz++23065dOyZMmEBEREQeRWiMMfnHrizOYrkzXnEhVxbZ2dlER0cDnsJ/X331FYsXL7ZEYYwptCxZnMWyXYepVaEkNSuc36ztmJgYevbsSdu2bYmNjUVEuPnmmwkODs79YGOMKaAsWeRAVVm28/zGKzIzM3njjTdo3rw5q1atYsyYMdSqVfDW6TbGmAthYxY52H88lYMn0mhVt4JP+6elpdGlSxeWLVvGjTfeyPvvv2+JwhgTUOzKIgcb444DEB5W7pz7ZWdnAxAaGkrPnj2ZMmUK3377rSUKY0zAsWSRg03xnmTR+BzJ4vfff6dly5YsXboUgFGjRnHrrbdahVhjTECyZJGDTfFJ1K1UijKhZ/bSJScn8+ijj9KxY0eOHDlCSkqKCxEaY0z+smSRg03xx3Psgpo/fz7NmjXjrbfeYujQoURHR9OtW7f8D9AYY/KZDXCf5mR6JjsPJdOn5ZnjDkuXLqVYsWIsXLiQLl26uBCdMca4w64sTrN5fxKq0CSsLAAzZszghx9+AODxxx9n7dq1liiMMUVOoUkWItJbRLaISIyIjPDX95wa3K5aLJX+/fvTp08fxo4dC3gK/5Us6d+lVY0xpiAqFN1QIhIMvAdcDcQCy0VkhqpuzOvv2hh3jKytC7mq40BOnDjBCy+8wFNPPZXXX2OMMYVKoUgWQFsgRlV3AIjIFKAPkOfJYuHP84mdNpr27dszYcIEwsPD8/orjDGm0CksyaIWsNfrdSzQ7vSdRGQIMASgbt26F/RFV191Nc2rvc87I4dYPSdjjHEUlmSR00w3PaNBdTwwHiAyMvKM933xrxsj4EarDmuMMd4KywB3LFDH63VtIM6lWIwxpsgpLMliOdBIROqLSAjQH5jhckzGGFNkFIpuKFXNFJFhwGwgGPhYVaNdDssYY4qMQpEsAFT1B+AHt+MwxpiiqLB0QxljjHGRJQtjjDG5smRhjDEmV5YsjDHG5EpUL2juWoEnIonA7gs8vApwMA/DKQzsnIuGonbORe184eLP+RJVrXp6Y8Ami4shIitUNdLtOPKTnXPRUNTOuaidL/jvnK0byhhjTK4sWRhjjMmVJYucjXc7ABfYORcNRe2ci9r5gp/O2cYsjDHG5MquLIwxxuTKkoUxxphcWbLwIiK9RWSLiMSIyAi348krIvKxiCSIyAavtkoiMkdEtjnPFb3eG+n8DLaISC93or44IlJHRH4WkU0iEi0iDzvtAXveIlJCRJaJyFrnnJ9z2gP2nAFEJFhEVovI987rgD5fABHZJSLrRWSNiKxw2vx73qpqD8+4TTCwHWgAhABrgXC348qjc+sCtAY2eLW9BoxwtkcArzrb4c65hwL1nZ9JsNvncAHnHAa0drbLAludcwvY88azomQZZ7s4sBRoH8jn7JzHo8BnwPfO64A+X+dcdgFVTmvz63nblcWf2gIxqrpDVdOBKUAfl2PKE6r6C3D4tOY+wCRnexLQ16t9iqqmqepOIAbPz6ZQUdV4VV3lbCcBm/Cs5R6w560eJ5yXxZ2HEsDnLCK1geuAj7yaA/Z8c+HX87Zk8adawF6v17FOW6Cqrqrx4PnFClRz2gPu5yAi9YBWeP7SDujzdrpk1gAJwBxVDfRzfht4Esj2agvk8z1FgZ9EZKWIDHHa/HrehWbxo3wgObQVxfuKA+rnICJlgK+Bv6vqcZGcTs+zaw5the68VTULaCkiFYBpItL0HLsX6nMWkeuBBFVdKSLdfDkkh7ZCc76n6aSqcSJSDZgjIpvPsW+enLddWfwpFqjj9bo2EOdSLPnhgIiEATjPCU57wPwcRKQ4nkTxqap+4zQH/HkDqOpRYAHQm8A9507AjSKyC0+3cQ8R+S+Be75/UNU45zkBmIanW8mv523J4k/LgUYiUl9EQoD+wAyXY/KnGcAgZ3sQMN2rvb+IhIpIfaARsMyF+C6KeC4hJgCbVPVNr7cC9rxFpKpzRYGIlASuAjYToOesqiNVtbaq1sPz73W+qt5BgJ7vKSJSWkTKntoG/gJswN/n7faofkF6ANfiuWtmO/C02/Hk4Xl9DsQDGXj+yogCKgPzgG3OcyWv/Z92fgZbgGvcjv8Cz/lKPJfa64A1zuPaQD5voDmw2jnnDcA/nfaAPWev8+jGn3dDBfT54rljc63ziD71u8rf523lPowxxuTKuqGMMcbkypKFMcaYXFmyMMYYkytLFsYYY3JlycIYY0yubAa3MecgIi8Ds4EKQGNVfcXdiDxE5N/ACVV93e1YTNFgVxbGnFs7PDWlugKLcttZRPL8DzDxsH+rxlX2P6AxORCR0SKyDrgCWAIMBsaJyD9z2HeiiLwpIj8Dr4rIpSLyo1PkbZGINHb2qy4i05z1JtaKSEen/VER2eA8/u601RPPWhzvA6uAOiLytLMewVzgcq/vf0hENorIOhGZ4ucfjSmibFKeMWchIm2BO/Gsl7BAVTudZb+JQBWgj6pmicg84H5V3SYi7YCXVbWHiHwBLFHVt0UkGCgDNAQm4ll3QvBcxdwBHAF2AB1V9XcRaePs1w5P9/Eq4ANVfV1E4oD6qpomIhXUUxfKmDxlYxbGnF0rPGVCGgMbc9n3SydRlAE6Al96VbgNdZ57AAPhj+qwx0TkSmCaqiYDiMg3QGc89Xx2q+rvzrGdnf1OOvt51y1bB3wqIt8C317QmRqTC0sWxpxGRFri+Su+NnAQKOVpljVAB1VNyeGwZOc5CDiqqi19/bpzvJd82uuzdQNch2c1xBuBZ0UkQlUzffx+Y3xiYxbGnEZV1zi/7E8txTof6KWqLc+SKLyPPQ7sFJF+8MfgdAvn7XnAUKc9WETKAb8AfUWklFNB9K/kPJD+C/BXESnpVBy9wfmcIKCOqv6MZxGgCni6t4zJU5YsjMmBiFQFjqhqNp5bZnPrhvJ2OxAlIqeqgp5anvdhoLuIrAdWAhHqWfp1Ip6S0UuBj1R19ekf6Oz3BZ5usa/5M6EEA/91PnM18JaNWRh/sAFuY4wxubIrC2OMMbmyZGGMMSZXliyMMcbkypKFMcaYXFmyMMYYkytLFsYYY3JlycIYY0yu/h+rd9kwv82LRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# Create a new dataframe for Gains\\ngains_df = pd.gains_df = pd.DataFrame(Score_Analysis[\\\"Expected Spending\\\"])\\n\\n# Sort values in Gains Data Frame\\ngains_df = gains_df.sort_values(by=[\\\"Expected Spending\\\"],\\n                                ascending=False).reset_index(\\n    drop=True\\n)\\n\\n# Plot a gains chart\\ngainsChart(gains_df[\\\"Expected Spending\\\"])\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Create a new dataframe for Gains\\ngains_df = pd.gains_df = pd.DataFrame(Score_Analysis[\\\"Expected Spending\\\"])\\n\\n# Sort values in Gains Data Frame\\ngains_df = gains_df.sort_values(by=[\\\"Expected Spending\\\"], ascending=False).reset_index(\\n    drop=True\\n)\\n\\n# Plot a gains chart\\ngainsChart(gains_df[\\\"Expected Spending\\\"])\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new dataframe for Gains\n",
    "gains_df = pd.gains_df = pd.DataFrame(Score_Analysis[\"Expected Spending\"])\n",
    "\n",
    "# Sort values in Gains Data Frame\n",
    "gains_df = gains_df.sort_values(by=[\"Expected Spending\"], ascending=False).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# Plot a gains chart\n",
    "gainsChart(gains_df[\"Expected Spending\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the gains curve, for instance, if we select the top 20% of cases (100 records) based on the model, we will select about 60% of the target class. If we select the top 80% of cases, we would expect 100% of the target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"liftChart(gains_df[\\\"Expected Spending\\\"], labelBars=True)\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"liftChart(gains_df[\\\"Expected Spending\\\"], labelBars=True)\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "liftChart(gains_df[\"Expected Spending\"], labelBars=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the top 20% of observations based on model probability, this selection contains 2.1x higher % target class cases compared to a random selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Using this cumulative gains curve, estimate the gross profit that would result from mailing to the 180,000 names on the basis of your data mining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers targeted from the 180,000 mailing list:  36000.0\n",
      "\n",
      "Total cost to mail for targeted customers: $ 72000.0\n",
      "\n",
      "Estimate gross profit that the firm could expect from the remaining 36,0000 names: $ 479505.8\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Expected average spending per customer\\navg_spending = Score_Analysis[\\\"Expected Spending\\\"].mean()\\n\\n# Number of Customers targeted among the 180,000\\n# Based on Gains Curve, We will target 20% of 180,0000\\nnumber_purchasers = 180000 * 0.2  \\n\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * number_purchasers\\navg_profit = total_spending - cost\\n\\nprint(\\\"Number of customers targeted from the 180,000 mailing list: \\\",\\n      number_purchasers)\\nprint(\\\"\\\\nTotal cost to mail for targeted customers: $\\\", cost)\\nprint(\\n    \\\"\\\\nEstimate gross profit that the firm could expect from the remaining 36,0000 names: $\\\",\\n    round(avg_profit, 2),\\n)\";\n",
       "                var nbb_formatted_code = \"# Expected average spending per customer\\navg_spending = Score_Analysis[\\\"Expected Spending\\\"].mean()\\n\\n# Number of Customers targeted among the 180,000\\n# Based on Gains Curve, We will target 20% of 180,0000\\nnumber_purchasers = 180000 * 0.2\\n\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * number_purchasers\\navg_profit = total_spending - cost\\n\\nprint(\\\"Number of customers targeted from the 180,000 mailing list: \\\", number_purchasers)\\nprint(\\\"\\\\nTotal cost to mail for targeted customers: $\\\", cost)\\nprint(\\n    \\\"\\\\nEstimate gross profit that the firm could expect from the remaining 36,0000 names: $\\\",\\n    round(avg_profit, 2),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expected average spending per customer\n",
    "avg_spending = Score_Analysis[\"Expected Spending\"].mean()\n",
    "\n",
    "# Number of Customers targeted among the 180,000\n",
    "# Based on Gains Curve, We will target 20% of 180,0000\n",
    "number_purchasers = 180000 * 0.2  \n",
    "\n",
    "total_spending = number_purchasers * avg_spending\n",
    "\n",
    "# Expected average profit per customer (with cost of mailing)\n",
    "cost = 2 * number_purchasers\n",
    "avg_profit = total_spending - cost\n",
    "\n",
    "print(\"Number of customers targeted from the 180,000 mailing list: \",\n",
    "      number_purchasers)\n",
    "print(\"\\nTotal cost to mail for targeted customers: $\", cost)\n",
    "print(\n",
    "    \"\\nEstimate gross profit that the firm could expect from the remaining 36,0000 names: $\",\n",
    "    round(avg_profit, 2),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we were to target 20% of the customers in the 180,000 mailing list, the expected gross profit would be about 480,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers targeted from the 180,000 mailing list:  144000.0\n",
      "\n",
      "Total cost to mail for targeted customers: $ 288000.0\n",
      "\n",
      "Estimate gross profit that the firm could expect from the remaining 144,0000 names: $ 1918023.2\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Expected average spending per customer\\navg_spending = Score_Analysis[\\\"Expected Spending\\\"].mean()\\n\\n# Number of Customers targeted among the 180,000\\nnumber_purchasers = 180000 * 0.8  \\n# Based on Gains CurveWe will target 80% of 180,0000\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * number_purchasers\\navg_profit = total_spending - cost\\n\\nprint(\\\"Number of customers targeted from the 180,000 mailing list: \\\",\\n      number_purchasers)\\nprint(\\\"\\\\nTotal cost to mail for targeted customers: $\\\", cost)\\nprint(\\n    \\\"\\\\nEstimate gross profit that the firm could expect from the remaining 144,0000 names: $\\\",\\n    round(avg_profit, 2),\\n)\";\n",
       "                var nbb_formatted_code = \"# Expected average spending per customer\\navg_spending = Score_Analysis[\\\"Expected Spending\\\"].mean()\\n\\n# Number of Customers targeted among the 180,000\\nnumber_purchasers = 180000 * 0.8\\n# Based on Gains CurveWe will target 80% of 180,0000\\ntotal_spending = number_purchasers * avg_spending\\n\\n# Expected average profit per customer (with cost of mailing)\\ncost = 2 * number_purchasers\\navg_profit = total_spending - cost\\n\\nprint(\\\"Number of customers targeted from the 180,000 mailing list: \\\", number_purchasers)\\nprint(\\\"\\\\nTotal cost to mail for targeted customers: $\\\", cost)\\nprint(\\n    \\\"\\\\nEstimate gross profit that the firm could expect from the remaining 144,0000 names: $\\\",\\n    round(avg_profit, 2),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expected average spending per customer\n",
    "avg_spending = Score_Analysis[\"Expected Spending\"].mean()\n",
    "\n",
    "# Number of Customers targeted among the 180,000\n",
    "number_purchasers = 180000 * 0.8\n",
    "# Based on Gains CurveWe will target 80% of 180,0000\n",
    "total_spending = number_purchasers * avg_spending\n",
    "\n",
    "# Expected average profit per customer (with cost of mailing)\n",
    "cost = 2 * number_purchasers\n",
    "avg_profit = total_spending - cost\n",
    "\n",
    "print(\"Number of customers targeted from the 180,000 mailing list: \", number_purchasers)\n",
    "print(\"\\nTotal cost to mail for targeted customers: $\", cost)\n",
    "print(\n",
    "    \"\\nEstimate gross profit that the firm could expect from the remaining 144,0000 names: $\",\n",
    "    round(avg_profit, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we were to target 80% of the customers in the 180,000 mailing list, the expected gross profit would be about 1.92 million.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Briefly explain, in two to three paragraphs, the business objective, the data mining models used, why they were used, the model results, and your recommendations to your non-technical stakeholder team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tayko, a software catalog firm, mails out catalogs to their mailing list in an attempt to expand its customer base. Data mining techniques were used to select the names that have the best chance of performing well instead of randomly selecting or sending all customers a catalog. To achieve this, Tayko has supplied its customer list of 200,000 names to the pool in order to implement a predictive model to choose the best candidates from the mailing list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20,000 of the 200,000 names were used as a sample. Among that sample, a stratified sample 1000 purchasers and 1000 non purchasers were selected to optimize the performance of the data mining techniques. Therefore, the predictive model will adjust the true probability of purchase of the 20,000 samples. Logistic regression with L2 penalty was used to predict purchasers and probability of purchasers. To reduce the predictors, near zero coefficients were removed to avoid model overfitting. In addition, multiple linear regression and regression trees were implemented to predict spending for each customer. For linear regression, stepwise regression was used to reduce the predictors for modeling. Moreover, two regression tree models were used: decision tree and random forest. The tuned random forest regressor yielded the best results among all predictive spending models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, the gross profit of sending out catalogs is around 1.6 million if the firm randomly selected from the pool from the remaining 180,000 names. From the data mining techniques, a cumulative gains chart of the expected spending was created for the test set. Based on the gains curve, we could expect near 100 percent of the target class by selecting the top 80 percent of cases. Therefore, 144,000 names will be targeted among the 180,000 names in the pool. By doing so, the cost of mailing the catalogs is reduced from 360,000 to 288,000. Moreover, the firm can estimate a gross profit of 1.92 million using the predictive model, which is an increase of 300,000 from randomly selecting names. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
